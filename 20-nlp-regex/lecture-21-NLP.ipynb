{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science – Practical Natural Language Processing (NLP)\n",
    "*COMP 5360 / MATH 4100, University of Utah, http://datasciencecourse.net/* \n",
    "\n",
    "In this lecture, we introduce some practical NLP following up on the theoretical lecture. We will do some basic text processing followed by analyzing sentiment for movie reviews. For this purpose, we'll introduce  the [Natural Language Toolkit (NLTK)](http://www.nltk.org/), a Python library for natural language processing. \n",
    "\n",
    "We won't cover NLTK or NLP extensively here – this lecture is meant to give you a few pointers if you want to use NLP in the future, e.g., for your project.\n",
    "\n",
    "Also, there is a well-regarded alternative to NLTK: [Spacy](https://spacy.io/). If you're planning to use a lot of NLP in your project, that might be worth checking out. \n",
    "\n",
    "**Reading:** \n",
    "\n",
    "[S. Bird, E. Klein, and E. Loper, *Natural Language Processing with Python – Analyzing Text with the Natural Language Toolkit*](http://www.nltk.org/book/). \n",
    "\n",
    "\n",
    "[C. Manning and H. Schütze, *Foundations of Statistical Natural Language Processing* (1999).](http://nlp.stanford.edu/fsnlp/)\n",
    "\n",
    "[D. Jurafsky and J. H. Martin, *Speech and Language Processing* (2016).](https://web.stanford.edu/~jurafsky/slp3/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next week:** guest lecturer Dr. Ana Marasovic will be speaking about state-of-the-art techniques!   \n",
    "\n",
    "We also recommend last year's guest lecture, by Yichu Zhou: [https://youtu.be/WengvXA8XzM](https://youtu.be/WengvXA8XzM)\n",
    "\n",
    "*Note: We will also be demonstrating CoLab for collaborative notebook editing in the extra time at this lecture.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Tasks\n",
    "\n",
    "There are several tasks we might perform in understand text data:\n",
    "* Part of speech tagging (what are the nouns, verbs, adjectives, prepositions).\n",
    "+ Information Extraction\n",
    "+ Sentiment Analysis (determine the attitude of text, e.g., is it positive or negative).\n",
    "+ Semantic Parsing (translate natural language into a formal meaning representation).\n",
    "\n",
    "The current strategy for many NLP tasks is to find a good way to represent the text (\"extract features\") and then to use machine learning / statistics tools, such as classification or clustering. \n",
    "\n",
    "Our goal today is to use NLTK + scikit-learn to do some basic NLP tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install datasets and models\n",
    "\n",
    "To use NLTK, you must first download and install the datasets and models. Run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     /Users/kisaacs/nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and setup\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (15, 9)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of NLTK\n",
    "\n",
    "We have downloaded a set of text corpora above. Here is a list of these texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first 20 words of text1 – Moby Dick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'Moby',\n",
       " 'Dick',\n",
       " 'by',\n",
       " 'Herman',\n",
       " 'Melville',\n",
       " '1851',\n",
       " ']',\n",
       " 'ETYMOLOGY',\n",
       " '.',\n",
       " '(',\n",
       " 'Supplied',\n",
       " 'by',\n",
       " 'a',\n",
       " 'Late',\n",
       " 'Consumptive',\n",
       " 'Usher',\n",
       " 'to',\n",
       " 'a',\n",
       " 'Grammar']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Statistics\n",
    "\n",
    "We can check the length of a text. The text of Moby Dick is 26,0819 words, whereas Monty Python and the Holy Grail has 16,967 words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260819"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16967"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check for the frequency of a word. The word \"swallow\" appears 10 times in Monty Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text6.count(\"swallow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might want to know the context in which \"swallow\" appears in the text\n",
    "\n",
    "\"You shall know a word by the company it keeps.\" – John Firth\n",
    "\n",
    "Use the [`concordance`](http://www.nltk.org/api/nltk.html#nltk.text.Text.concordance) function to print out the words just before and after all occurrences of the word \"swallow\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 10 of 10 matches:\n",
      " is a temperate zone . ARTHUR : The swallow may fly south with the sun or the h\n",
      "be carried . SOLDIER # 1 : What ? A swallow carrying a coconut ? ARTHUR : It co\n",
      "o maintain air - speed velocity , a swallow needs to beat its wings forty - thr\n",
      ": It could be carried by an African swallow ! SOLDIER # 1 : Oh , yeah , an Afri\n",
      "OLDIER # 1 : Oh , yeah , an African swallow maybe , but not a European swallow \n",
      " swallow maybe , but not a European swallow . That ' s my point . SOLDIER # 2 :\n",
      " and Sir Bedevere , not more than a swallow ' s flight away , had discovered so\n",
      "omething . Oh , that ' s an unladen swallow ' s flight , obviously . I mean , t\n",
      " air - speed velocity of an unladen swallow ? ARTHUR : What do you mean ? An Af\n",
      "o you mean ? An African or European swallow ? BRIDGEKEEPER : Huh ? I -- I don '\n"
     ]
    }
   ],
   "source": [
    "text6.concordance(\"swallow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words that occur with notable frequencey are \"fly\" or \"flight\", \"unladen\", \"air\", \"African\", \"European\". We can learn about what a swallow can do or properties of a swallow by this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we look for Ishmael in Moby Dick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 20 of 20 matches:\n",
      "SONG . CHAPTER 1 Loomings . Call me Ishmael . Some years ago -- never mind how \n",
      "ED STATES . \" WHALING VOYAGE BY ONE ISHMAEL . \" BLOODY BATTLE IN AFFGHANISTAN .\n",
      "f silver ,-- So , wherever you go , Ishmael , said I to myself , as I stood in \n",
      "de to lodge for the night , my dear Ishmael , be sure to inquire the price , an\n",
      "nkling glasses within . But go on , Ishmael , said I at last ; don ' t you hear\n",
      "g and teeth - gnashing there . Ha , Ishmael , muttered I , backing out , Wretch\n",
      "emen who had gone before me . Yes , Ishmael , the same fate may be thine . But \n",
      " ? thought I . Do you suppose now , Ishmael , that the magnanimous God of heave\n",
      "l , which , if left to myself , I , Ishmael , should infallibly light upon , fo\n",
      " Bildad . Now then , my young man , Ishmael ' s thy name , didn ' t ye say ? We\n",
      "say ? Well then , down ye go here , Ishmael , for the three hundredth lay .\" \" \n",
      "why don ' t you speak ? It ' s I -- Ishmael .\" But all remained still as before\n",
      "l fear ! CHAPTER 41 Moby Dick . I , Ishmael , was one of that crew ; my shouts \n",
      "lain , would be to dive deeper than Ishmael can go . The subterranean miner tha\n",
      "oul ; thou surrenderest to a hypo , Ishmael . Tell me , why this strong young c\n",
      " snows of prairies ; all these , to Ishmael , are as the shaking of that buffal\n",
      "ubtle meanings , how may unlettered Ishmael hope to read the awful Chaldee of t\n",
      "onditional skeleton . But how now , Ishmael ? How is it , that you , a mere oar\n",
      " for exhibition ? Explain thyself , Ishmael . Can you land a full - grown whale\n",
      "le witness have you hitherto been , Ishmael ; but have a care how you seize the\n"
     ]
    }
   ],
   "source": [
    "text1.concordance(\"Ishmael\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see a lot of \"I\"s. We could probably infer that Ishmael is the narrator based on that. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see what other words frequently appear in the same context using the  [`similar`](http://www.nltk.org/api/nltk.html#nltk.text.Text.similar) function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plover\n"
     ]
    }
   ],
   "source": [
    "text6.similar(\"swallow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unladen\n"
     ]
    }
   ],
   "source": [
    "text6.similar(\"african\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "castle lord what horse robinson scratch draw bristol model god grail\n",
      "sniff sacrifice bride test mistake\n"
     ]
    }
   ],
   "source": [
    "text6.similar(\"coconut\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that 'african' and 'unladen' both appeared in the text with the same word just before and just after. To see what the phrase is, we can use the [`common_contexts`](http://www.nltk.org/api/nltk.html#nltk.text.Text.concordance) function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an_swallow\n"
     ]
    }
   ],
   "source": [
    "text6.common_contexts([\"African\", \"unladen\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that both \"an unladen swallow\" and \"an african swallow\" appear in the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 2 of 2 matches:\n",
      "overed something . Oh , that ' s an unladen swallow ' s flight , obviously . I \n",
      "t is the air - speed velocity of an unladen swallow ? ARTHUR : What do you mean\n",
      "\n",
      "Displaying 4 of 4 matches:\n",
      "IER # 2 : It could be carried by an African swallow ! SOLDIER # 1 : Oh , yeah ,\n",
      "llow ! SOLDIER # 1 : Oh , yeah , an African swallow maybe , but not a European \n",
      "LDIER # 1 : But then of course a -- African swallows are non - migratory . SOLD\n",
      "ow ? ARTHUR : What do you mean ? An African or European swallow ? BRIDGEKEEPER \n"
     ]
    }
   ],
   "source": [
    "text6.concordance(\"unladen\")\n",
    "print()\n",
    "text6.concordance(\"african\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dispersion plot\n",
    "\n",
    "`text4` is the Inaugural Address Corpus which includes inaugural addresses going back to 1789. \n",
    "We can use a dispersion plot to see where in a text certain words appear, and hence how the language of the address has changed over time. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fellow - Citizens of the Senate and of the House of Representatives : Among the vicissitudes incident to life no event could have filled me with greater anxieties than that of which the notification was transmitted by your order , and received on the 14th day of the present month . On the one hand , I was summoned by my Country , whose voice I can never hear but with veneration and love , from a retreat which I had chosen with the fondest predilection , and , in my flattering hopes , with an immutable decision , as\n",
      "\n",
      "and justice , did not die on our watch , but thrived ; that America secured liberty at home and stood once again as a beacon to the world . That is what we owe our forebearers , one another , and generations to follow . So with purpose and resolve we turn to those tasks of our time , sustained by faith , driven by conviction , and devoted to one another and the country we love with all our hearts . May God bless America , and may God protect our troops . Thank you , America .\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(text4[:100]))\n",
    "print(\"\")\n",
    "\n",
    "print(\" \".join(text4[-100:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "set_ticks() got an unexpected keyword argument 'color'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtext4\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispersion_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcitizens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdemocracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfreedom\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mduty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAmerica\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGod\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmilitary\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/nltk/text.py:556\u001b[0m, in \u001b[0;36mText.dispersion_plot\u001b[0;34m(self, words)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;124;03mProduce a plot showing the distribution of the words through the text.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;124;03mRequires pylab to be installed.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;124;03m:seealso: nltk.draw.dispersion_plot()\u001b[39;00m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdraw\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispersion_plot\n\u001b[0;32m--> 556\u001b[0m \u001b[43mdispersion_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/nltk/draw/dispersion.py:49\u001b[0m, in \u001b[0;36mdispersion_plot\u001b[0;34m(text, words, ignore_case, title)\u001b[0m\n\u001b[1;32m     47\u001b[0m _, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots()\n\u001b[1;32m     48\u001b[0m ax\u001b[38;5;241m.\u001b[39mplot(xs, ys, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_yticks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_ylim(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(words))\n\u001b[1;32m     51\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_title(title)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/matplotlib/axes/_base.py:63\u001b[0m, in \u001b[0;36m_axis_method_wrapper.__set_name__.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/matplotlib/cbook/deprecation.py:451\u001b[0m, in \u001b[0;36m_make_keyword_only.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m idx:\n\u001b[1;32m    446\u001b[0m     warn_deprecated(\n\u001b[1;32m    447\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    450\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: set_ticks() got an unexpected keyword argument 'color'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3AAAAIICAYAAAAv7AzPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA8TUlEQVR4nO3de4yldX04/vfAoLLcZ4dLFqWKgI3rBS0oxXplbJNWqiFGkUqC0K9REIK3AuYXTVuJqyuFtEIw0aIhIVvTiN1tbG2n3qLEBMHVddVdUbSYxV1mF+guy7rMzPP7gz3HM2ee65lzzpzP7uuVbOac5/k8n8/7c3ue82bOLmNZlmUBAADAyDtsuQMAAACgHgkcAABAIiRwAAAAiZDAAQAAJEICBwAAkAgJHAAAQCIkcAAAAIkYH1TF27ZtG1TVPZmcnIyZmZnlDoMwF6PGfIwW8zE6zMVoMR+jxXyMDnMxWjrnY9WqVQNpw2/gAAAAEiGBAwAASIQEDgAAIBESOAAAgERI4AAAABIhgQMAAEiEBA4AACAREjgAAIBESOAAAAASIYEDAABIhAQOAAAgERI4AACAREjgAAAAEiGBAwAASIQEDgAAIBESOAAAgESMVxXYtm1b3Hzzze33O3bsiLe97W3xF3/xFwMNDAAAgIUqfwO3atWqWLt2baxduzY++clPxjOe8Yx4xSteMYzY+m5u7Q0xv/6uiIj2z+7Xne/zysyvv2vR+c5yeW20jnVe2zreWWd3HGUxta7trqfONXlxt+u67opF/Sy6Jq8/RTG0Xrfq70XZGHWOx4LjHf0pi6tJW1XXlh1vam7tDTF33RUL5m7u6osL13LE032eX3/XojVSZ311vm6NQWc9i9rqGvc6e6ms7bJjnefq7JeifdGpe1yq5q3Xea3T/1a8e9Z9rvCaqj1Zdrxb0V5sx9Ngr+bFUGesmt57867Jq7N7jfRrXRYdb7ouuvdV0xiatNnr+mhab5O2l6rzPlin7n7MWT+urTPneW0N+77UvgdcfXHPdfSrfJ6ycay7DvKeXUVj3STmOvfosvK5n8tyPkN230Naz43WnJV9ZqvTZh1NPle1PpfUvffVbfNQ1ugrlJs2bYpTTjklTjzxxEHFM1hbN0e2YV1ERPtn9+vO93llsg3rFp1fcH1eGweOdV7bOt5ZZ3ccpTEduLa7njrX5MbdsuuRRf0suiavP0UxtF8fqL8XpWPUOR6dOvpTGleDtqquLTve2NbNT/ehc+727S1cyxERseuRp491rZE666vzdXsMOupZVEfXuNfZS2Vtlx3rPFdrvxTsiwW6xqVq3nqd11r9PxDvE//yz4XXVO3JsuOLFOzF9nUN9mpeDHXGqum9N++avDq710i/1mXR8abrYtH+bBhDkzZ7Xh8N623S9lJ13gfr1N2POevLtTXmPK+tYd+X2sf37e25jn6Vz1UyjrXXQc6zq2ism8Rc5x5dVj63bM5nyO57SOu50Zqzss9stdqsodHnqgOfS+re++q2eShrlMB997vfjVe96lWDigUAAIASlX8HrmV2djbuu+++uOSSS3LPT09Px/T0dERErFmzJiYnJ/sTYZ+Mj/++q5OTk7H9wM+IWPC6831eme05dXSXyzvfqajOznPdutsqiq2sH2V15F1TFGteX/Ped17XeX58fLyn9ZFXf147Rf0piytvHOq0VdXuUnWvjby1lNe3zvOdx/Jiau2NOuuybBzL3peNR9k6LCrfHVdRmTptd9ZTNW+9zmud/jfZn3nXFdXXNKa615fVVbbeqq6rur/V6VenXsdoe+Tfq5qu17IYm45PL232uj6a1tuk7V615qPOvakq1qXEMoj7QNk1UXFdv+Opu0a6nx1LabOJXvdF1ee+lqWslTr36LLyRe13qvMZrewzW/d1eW3W0eRzVdHn4KW2Oap6/ZzbqI26BX/wgx/E8573vDj++ONzz09NTcXU1FT7/czMzJKD66fOgWzF1hljd7xVZbrP17m+rJ6i92V1lsVTdU0v8VW1Uff97OzsktZH0bVVx8vi6rXOXq7tVdlc1Y0hr1xrb9Rdl73Of521XXWsaZk6bXefb1K2iV72dt392cuYl52ve31VXb3MYZ37Wy9x9TJGRfeqXvvayzVN902dcr2MY6/tN3nGVZmcnOzpPl50bhDPoeW6rt/11lkjec+OpbTZrzrqnmvy7O71XtjL86/X51Wvz5E6bdaJpSy2quuW0uYo6rxXrVq1aiBt1P4Kpa9PAgAALK9av4Hbt29f/OhHP4p3v/vdg45nsM5aHWMveHFERIxd+Pt/Xanzdef7vDJVx3Lb6DjWHU9e+3kWtXXg2rJ6iq7Jjbtl4sR6deVdn9PP7vLZd/9ncZs1lY5T53h0quhPUb1lbVVdW3V9I2etjpjZETF5Urve7L/XR5z2vNy1HBEREyfG2KsuiGzLpgX15K7BnHi757qznrw5L6onr66qtsuO1TnXWaYVd9W66RyXqrp7ndda/Tkwlke9/fLYV3BN5f2n5PgiE/n/GFX7uoLzpdcUvG96XVk/e5mjfq3LuvVX6VyfVeV6OVdWrvb6aFhvk7aXqvM+WKfufsxZX64tek4tsa1+35fax5+1ou9t92UNlIxj7XVQ8eyqe66sbNP7TGG5gs9WnfeQ1nOjNWe1PrNVxFal0eeqA59LIqLWva9um4eysSzLskFUvG3btkFU27O8r16wPMzFaDEfo8V8jA5zMVrMx2gxH6PDXIyWkfoKJQAAAMtLAgcAAJAICRwAAEAiJHAAAACJkMABAAAkQgIHAACQCAkcAABAIiRwAAAAiZDAAQAAJEICBwAAkAgJHAAAQCIkcAAAAImQwAEAACRCAgcAAJAICRwAAEAiJHAAAACJkMABAAAkQgIHAACQCAkcAABAIiRwAAAAiZDAAQAAJEICBwAAkAgJHAAAQCIkcAAAAImQwAEAACRCAgcAAJAICRwAAEAiJHAAAACJkMABAAAkQgIHAACQCAkcAABAIiRwAAAAiZDAAQAAJEICBwAAkAgJHAAAQCIkcAAAAImQwAEAACRCAgcAAJAICRwAAEAiJHAAAACJkMABAAAkQgIHAACQCAkcAABAIiRwAAAAiZDAAQAAJEICBwAAkAgJHAAAQCIkcAAAAImQwAEAACRCAgcAAJAICRwAAEAiJHAAAACJkMABAAAkQgIHAACQCAkcAABAImolcE888UTcdNNNce2118b73//+2Lp166Dj4hA1v/6u5Q6hkbx4l6MPrTZTGz9g9Myvv6v9p/U+Vb3G3nnd3NUXF45H6/XcdVfE3NUX59bTeW1eG0Uxzq29oafYhyHlNdFEaw7q7oX59Xctuibv+rJzVcebHGtyvqmy+nppa379Xe09lDcWZeNzqKzHTrUSuDvuuCPOPvvsuOWWW2Lt2rVx6qmnDjouDlHZhnXLHUIjefEuRx9abaY2fsDoyTasa/9pvU9Vr7EvuG7f3sLxaL/e9UjEvr259XRem9dGYYxbN/cU+zCkvCYaOTAHdfdCtmHdomvyri87V3W8ybEm55sqq6+XtrIN69p7KG8sysbnkFmPHSoTuL1798ZPf/rTeMMb3hAREePj43HUUUcNPDAAAAAWGq8qsGPHjjj22GPjtttui1//+tdx+umnx2WXXRbPetazFpSbnp6O6enpiIhYs2ZNTE5ODibiHo2Pj49cTIeqsrnYHpHUPOXFuxx9aLXZS9v2xmgxH6PjUJ2L7R2ve72vDEIv89Fr7J3XlY1H5703Iv95ECXnysZ3VMY9z/Y4NPZH9xxVzUnnOihaJ1XnitrOi6tlfHy83W5VX/qlrL5e2ioau+5z3W0U7b3lNIy9UZnAzc3NxYMPPhiXX355nHnmmXHHHXfEV77ylbj44oXf9Z6amoqpqan2+5mZmf5HuwSTk5MjF9OhqmouUpunvHiXow+tNpu2bW+MFvMxOsxF7/eVQeh1PnqNveze3nmu6HWv9VVdMypmZ2dHOr5+6Z6jOn0uWyd1zlUd7z7WShaqYuv3fA3is1zdPne/H6W12HmvWrVq1UDaqPwK5cqVK2PlypVx5plnRkTEeeedFw8++OBAggEAAKBY5W/gjj/++Fi5cmVs27YtVq1aFZs2bYpnP/vZw4iNQ9DYhYv/Fa9RlhfvcvSh1WZq4weMnu77SMr3lV5jX3Dds1bE2Bv/Mvdc+/XEiRF7n2jUfuV9+6zVDSIerpTXRCMH5qDuM3bswosj27JpUdnu68vOVR1vcqzJ+abqrO2m9WX/vT73+rL+HjJrsctYlmVZVaFf/epXcfvtt8fs7GycdNJJceWVV8bRRx9des22bdv6FmQ/+CrM6DAXo8V8jBbzMTrMxWgxH6PFfIwOczFahvEVysrfwEVEPPe5z401a9YMJAAAAADqqfX/gQMAAGD5SeAAAAASIYEDAABIhAQOAAAgERI4AACAREjgAAAAEiGBAwAASIQEDgAAIBESOAAAgERI4AAAABIhgQMAAEiEBA4AACAREjgAAIBESOAAAAASIYEDAABIhAQOAAAgERI4AACAREjgAAAAEiGBAwAASIQEDgAAIBESOAAAgERI4AAAABIhgQMAAEiEBA4AACAREjgAAIBESOAAAAASIYEDAABIhAQOAAAgERI4AACAREjgAAAAEiGBAwAASIQEDgAAIBESOAAAgERI4AAAABIhgQMAAEiEBA4AACAREjgAAIBESOAAAAASIYEDAABIhAQOAAAgERI4AACAREjgAAAAEiGBAwAASIQEDgAAIBESOAAAgERI4AAAABIhgQMAAEiEBA4AACAREjgAAIBESOAAAAASIYEDAABIhAQOAAAgERI4AACAREjgAAAAEiGBAwAASEStBO6qq66KD37wg/HhD384rr/++kHHdFCYu+6KiIiYX39Xabn59XfVKnOwafWps2/dY1G336mNT3e8ZWOwlHqrzvUy1v2Q18fU5nCU5K2fubU31Cq/1PaW4/pB198aw6o90+92h1FfUZ1F94Je19HcdVcs+f5ddZ/MbXeA675K5/i24uiOp/O5l/enu665qy+u7Hfnnm/96TS39oZFbcytvaE9R3nP4u7+lPW1KLbS9XEgpqK6u18X7cmy951rMK9cdwx5637u6osXxVG2xor60PReUlaueyyK5rCzj6357lwjc2tviLmrL160V5t8Lqiak9bn4Lr10Uzt38B97GMfi7Vr18aaNWsGGc/BY9cjERGRbVhXWizbsK5WmYNNq0+dfesei7r9Tm18uuMtG4Ol1Ft1rpex7oe8PqY2h6Mkd/1s3Vyr/FLbW47rB11/awyr9ky/2x1GfUV1Ft4Lel1Hux5Z8v276j6Za4DrvsqC8W3F0RVP53Mv78+iuvbtrez3gj3f+tNp6+bFbWzd3J6jvGfxov6U9bUgttLxPhBTUd3dr4v2ZOn7jjWYW64rhtx1v2/vojjK1lhRH5reS8rKdY9F0Rwu6OOB+V6wRrZufrp/XXu1yeeCyjk58Dm4bn004yuUAAAAiRivW/DGG2+MiIg3vvGNMTU1tej89PR0TE9PR0TEmjVrYnJysk8h9sf4+PhQY9oeEZOTk+2fZeWiRplRG8+lGB9/etl1j0/3WNTtd2rj0x1v2Rgspd6qc61jnfMxDHl9TG0OB6npvSpv/UQ0WwtNLPf1g66/cwy756LpHluKQdQXBXV2r6E69+Cqc0Vt1a0n7z7Zmo+619Q91w+dfS56/ncez5O3j7uP593Hi+opqqvoWN51ReMcsXB/lD3Xiq6vuxaL7mt1n6VFfYsoX/d5P4viLutD3jW9fr7pjr1zLrr700TT/d/ZRtkcHKrP+WHkHLUSuL//+7+PiYmJePzxx+PjH/94rFq1Kl74whcuKDM1NbUgsZuZmelvpEs0OTk59Jha7dVpt6rMqI3nUrQWddH4dL6v2+/Uxqesz3nve6236tzMzMyi+RiWfvX5YNPLvapobpuUX2p7w7x+WPXPzs42Wqf97tcgxqmozqL77lL6u9T7d/fxzvmoe00v8SxFd3z9WD9Nn4m9PAeqzuXp3h9N7+m99LfX972u+7zre5mDpmNbp1zn8dnZ2UZ1ltXVz74eqs/5zuf4qlWrBtJGra9QTkxMRETEcccdF+eee2488MADAwkGAACAYpW/gdu3b19kWRZHHnlk7Nu3L370ox/FW9/61mHElraJEyMiYuzCi0uLVZ2vWyY1rT519q27n3X7ndr4lPVzKX0puzbvXL/abaoqFprJm8dsy6Za5Zfa3nJcP+j6m+6jfrW7nPUV3gvOWt1TfTFxYoy96oIlxdXTfbLXePsgd9y64sl77pXVlf33+hh741/mt9FdtmjPn7U6xl7w4kXHYmbHgjlq8vytcw8v7WNeTDnXVY1XaZsdazCvXLZl04IYcufvWSsWxVF2by3rQ1Xsdeqqet/9utXHbMumiJkdEZMnLaz8fx+MWHFU4Tro5fNr9xxUlad3Y1mWZWUFtm/fHp/+9KcjImJubi7+5E/+JC666KLKirdt29afCPtkOb5CST5zMVrMx2gxH6PDXIwW8zFazMfoMBejZRhfoaz8DdzJJ58ca9euHUjjAAAA1Od/IwAAAJAICRwAAEAiJHAAAACJkMABAAAkQgIHAACQCAkcAABAIiRwAAAAiZDAAQAAJEICBwAAkAgJHAAAQCIkcAAAAImQwAEAACRCAgcAAJAICRwAAEAiJHAAAACJkMABAAAkQgIHAACQCAkcAABAIiRwAAAAiZDAAQAAJEICBwAAkAgJHAAAQCIkcAAAAImQwAEAACRCAgcAAJAICRwAAEAiJHAAAACJkMABAAAkQgIHAACQCAkcAABAIiRwAAAAiZDAAQAAJEICBwAAkAgJHAAAQCIkcAAAAImQwAEAACRCAgcAAJAICRwAAEAiJHAAAACJkMABAAAkQgIHAACQCAkcAABAIiRwAAAAiZDAAQAAJEICBwAAkAgJHAAAQCIkcAAAAImQwAEAACRCAgcAAJAICRwAAEAiJHAAAACJkMABAAAkQgIHAACQCAkcAABAImoncPPz8/E3f/M3sWbNmkHGM1Dz6+9a9LP1uqm5tTcsuWyTOnqNs6rOJjHUrTPvdS/1dM9X0+uK4qpzrm4/6sRWpx957dWtu6hc61ydvnQfbzKPee00ba9fZare99pev9Z13XabtlE1zkX3vLzzTdsrm/vWPWap891kj+b1pfW6M5Z+zeNS6ql7/206flX1tsfjuiv60nZeuaL3/Rr/uuuqqSZrtlV+kPp1r+zndSw0CuO4Z93nFtznOg3y+VVXvz5r9uN5ebConcB99atfjVNPPXWQsQxctmHdop+t141t3bz0sg3q6DnOqjqb9KNunTmve6mne76aXlcUV51zdftRJ7Y6/chrr27dReVa5+r0pft4k3nMa6dpe/0qU/W+1/b6ta7rttu0japxLrrn5Z1v2l7Z3LfuMUud7yZ7NK8v7dcdsfRrHpdUT837b+Pxq6i3XXbXI31pO69c0fu+jX/NddVUkzXbLj9A/bpX9vM6FhqFcXziX/55wX2u0yCfX7X16bNmP56XB4taCdzOnTvj/vvvjwsuuGDQ8QAAAFBgvE6hL3zhC/HOd74znnzyycIy09PTMT09HRERa9asicnJyf5E2Cfj4093dXJyMrZ3/Gwda6pVx1LK9qOOpVhK/8vqbNVXFPP4+Hhlm52xNR2n1nVFcZXFnHes6bVFZerWU6d853VRUG57x+uyvnTujbJ4qmLIi2Mpa7+XMlXve22vyXg01V1f3nw0raP7eNE9L+98nXa7xyMv3u0LL1nSfDfZo3l9yet/nb7WvVf1uh56Ge86Zers2Sb3mF5iLHrfdK116pyPQTy/OuutW/cgns1N6+81hqXGXmd/HAoGvQbqxhCRv7cG+fyqq1/tVj0LRsUw9kZlAnfffffFcccdF6effnps3lz8K9CpqamYmppqv5+ZmelPhH3SGshWXJ3x9Rprk+uKyvajjqXqd71VYzs5OVm7zbz5ahpD2bG65ZteW1Smbj1N+11Vrqwv3XujzjVN4ljK2u+lTNX7Xtvrxz2jTt1F89GkjrzjRfF3n+91rpuswV7KNNmjTftcpO69ainroV97vLtM3fnoZ//q7sVe7+t58zHIzxr9nJtBxzGMzzHdmjzLD3ajMg5Fe2uQz6+6+tVu0893y6Fzb6xatWogbVQmcFu2bInvf//78YMf/CD2798fTz75ZPzjP/5jXHPNNQMJCAAAgHyVCdwll1wSl1xySUREbN68OTZs2JBs8jZ24cW5P3ty1uqll21Qx5JiLakz27Kp73XmvR5WPUVly+rIO1e3/Tqx1Vlvee01qbvuubrj02T8exmfpfatqEzV+17b69e6rttu0zaqxrloTfV6T6wzHq3j2ZZNMfaCFzeqs865ohjy+tJ+fdbqdiz9msdhPEca74WKettlJ07sS9t55fq11gp1zGU/tZ6LdesexLO5af29xjDo2A8VozCOR7398ti7d+/Tb7r2/yCfX7U1+cxcoh/Py4PFWJZlWd3CrQTu+uuvryy7bdu2JQXWb37VPzrMxWgxH6PFfIwOczFazMdoMR+jw1yMlpH4CmWn1atXx+rV/cmiAQAAaKb2/wcOAACA5SWBAwAASIQEDgAAIBESOAAAgERI4AAAABIhgQMAAEiEBA4AACAREjgAAIBESOAAAAASIYEDAABIhAQOAAAgERI4AACAREjgAAAAEiGBAwAASIQEDgAAIBESOAAAgERI4AAAABIhgQMAAEiEBA4AACAREjgAAIBESOAAAAASIYEDAABIhAQOAAAgERI4AACAREjgAAAAEiGBAwAASIQEDgAAIBESOAAAgERI4AAAABIhgQMAAEiEBA4AACAREjgAAIBESOAAAAASIYEDAABIhAQOAAAgERI4AACAREjgAAAAEiGBAwAASIQEDgAAIBESOAAAgERI4AAAABIhgQMAAEiEBA4AACAREjgAAIBESOAAAAASIYEDAABIhAQOAAAgERI4AACAREjgAAAAEiGBAwAASIQEDgAAIBESOAAAgERI4AAAABIhgQMAAEiEBA4AACARlQnc/v3744YbbogPf/jD8YEPfCC+9KUvDSOuoZtbe0NERMyvv2vRuc5j8+vvyi1zKKgam9SkHDv1meeFjMfoaT1XWs+hYelsb+66Kxa9znveteJsHe9+dub1ofNYk/XXOSZ1ruuMtzv2fqz7unXMrb2hPUadY9UPdepqjVnReuqc6zr1FNW1Z93n2uc6x72snvn1d8Xcey5asMbax6+++Omxu/riBeWL6i2LrbN80Rx0l2kd626zaC3lxbZgzN5z0e/39nVXtH+218aBMSjaQ53H59besODa9rEDx/PibZd7z0Xtsq16u1937rW8/do9ft1j2hlX3hhGRDv+dp86xmR+/V0x9//+ckG77XgOrIe8z+LdY3ooqUzgjjjiiPjYxz4Wa9eujU996lOxcePG2Lp16zBiG66tmyMiItuwbtGpzmPZhnW5ZQ4FVWOTmpRjpz7zvJDxGD3t58qB59DQdLa365FFr/Oed60428e7n515feg41mT9dY5Jnes64+2OvR/rvnYdWzf/fow6x6oPatXVGu+i9dQ513XqKajriX/55/a5znEvqyfbsC5ibnbBGmv/3Lf36bL79i4sX1RvSWwLyhfMQXeZ1rHuNovWUm5snbHMzf7+2l2PtH+242nNQ9Ee6jy+dfOCa9vHWsdz4m2Xm5v9fdlWvV2vF9x/cvbrovHrHtOOuPLGMCLa8bePd4xJ0X0mItrrIe+z+KIxPYRUJnBjY2PxrGc9KyIi5ubmYm5uLsbGxgYeGAAAAAuN1yk0Pz8f1113Xfz2t7+NP/uzP4szzzxzUZnp6emYnp6OiIg1a9bE5ORkfyNdovHx8dKYtkfE5ORk+2feudbryClzKKgam7qq5mJYeon9YDQq8zEoqc3zoOcjtfFYTsPaG9s7Xg9zbrqfbd2v85533bF2PzvrPEPr9rGz/e1R7zneWb4z9n6s+7p1bM851q95rRND2VzUraO7XNm8do97nc9Q3eW7xyxvLRbF3Ovntqo1X7QPytZ8UV+LlO2horHJMz4+vqC+qvaKyhb1p3uM88akrG/d1xTFWFS2qK6i65fbMJ4dtRK4ww47LNauXRtPPPFEfPrTn47//d//jdNOO21BmampqZiammq/n5mZ6W+kSzQ5OVkZU+t8XrnuY6PWv2GpMzZV6szFsIxKHMtplOZjUFLq3zDmI6XxWE7LsTeWs706r/OuLfpZp50mMc7Ozta6tmk/eollWNf1WlfZXDSJp2r88s7X/ZzQdL2Uxdzr57aqtVL3fK/rrGoP1a1rdna2Vvm687mUea26rsk8Nh2PUXm2dT47Vq1aNZA2Gv0rlEcddVSsXr06Nm7cOJBgAAAAKFb5G7j/+7//i8MPPzyOOuqo2L9/f/zoRz+KN7/5zcOIbbjOWh0REWMXXrzoVOexvPOHiqqxSU3KsVOfeV7IeIye1pxkWzYNt+EDz72IiJg4cdHront+tmVTjL3gxQvqaJftrDOnnSbrr9VW3evKntX9WPe162iNyQtevHCs+qBWDK3xzpuLiIVzXaeegrqOevvlse/AuVYfc+Prmv/sq/8acdwJC8qPXXhxZP+9PuK050X874MLyhfWWxLbgvId8ZWV6T5W1Hb38bx6IiLi8PEY+/O3RkRE9t3/ibFXXRDZd/8nYvKkp9fGd/8nv+2u+Wvvg5kd7WsjOu4XMztK482++q8Rz39Bfoxda7X7fOH4d49pnTGeODFi8qTf96ljTMZedcGCf4Skc+/Hs1YsqqvzdeeYHkrGsizLygr8+te/jltvvTXm5+cjy7L44z/+43jrW99aWfG2bdv6FmQ/HApfE0uFuRgt5mO0mI/RYS5Gi/kYLeZjdJiL0TKMr1BW/gbuD/7gD+JTn/rUQBoHAACgvkZ/Bw4AAIDlI4EDAABIhAQOAAAgERI4AACAREjgAAAAEiGBAwAASIQEDgAAIBESOAAAgERI4AAAABIhgQMAAEiEBA4AACAREjgAAIBESOAAAAASIYEDAABIhAQOAAAgERI4AACAREjgAAAAEiGBAwAASIQEDgAAIBESOAAAgERI4AAAABIhgQMAAEiEBA4AACAREjgAAIBESOAAAAASIYEDAABIhAQOAAAgERI4AACAREjgAAAAEiGBAwAASIQEDgAAIBESOAAAgERI4AAAABIhgQMAAEiEBA4AACAREjgAAIBESOAAAAASIYEDAABIhAQOAAAgERI4AACAREjgAAAAEiGBAwAASIQEDgAAIBESOAAAgERI4AAAABIhgQMAAEiEBA4AACAREjgAAIBESOAAAAASIYEDAABIhAQOAAAgERI4AACAREjgAAAAEiGBAwAASERlAjczMxN/+7d/G+9///vjAx/4QHz1q18dRlwDM7/+rtzXne/n19/V/tP5vmVu7Q0LfnbXU9VuVZnun51abea97+5bWT1V5tbeUDpW3YraLrq2aOznrruiMvZe+rOU60alnu65L6u3btmi6+uWadKH7nXRfSwv5rLyZW0UrZt+zV1RnWXrOu945+tWXXvWfa6y3e57T2vfdMdV1N+m+7nVZpP6uvucV24pMS5V1Toqu7/Pr79r0ZgPK7Zeri1aG8O+lza5h/Wq6t6Uty7L2i96DneOYWe/6tTfb2X31ibP324L+tWxH7rvBUXzWra3595zUelnsLxrqj7jNPm8ULX/u8t0Hit6VlVdVxRv95h2r6Huseped/Pr74pd/9+V+XNz3RWlnxNb5bvXdFnMRXNR9dktL4amZfm9ygTu8MMPj0svvTRuvvnmuPHGG+NrX/ta/OY3vxlGbAORbViX+7rzfbZhXftP5/u2rZsX/Oyup6rdqjLdPxdotZ3zvrtvpfVU2bq5dKy6FbVddG3R2MeuRypj76k/S7huZOrpnvuyemuWLby+ZpkmfVi0j7qP5cRcWr6kjaJ106+5K6qzbF3nHo+FY5ltWBdP/Ms/Vzfcfe85sG+64yrqb9P93GqzUX1dfc4rt5QYl6pqHZXd37MN6xaN+bBi6+XaorUx9Htpk3tYjyrvTTnrsqz9oufwgjHs7FeN+vut7N7a6PnbrbNfnfuh+15QMK+le3tutvQzWN41VZ9xmnxeqNz/kb8Oip6vRZ9b8j5H5v7sHNPuNdQ1Vt3rLtuwLp7avDF/bnY9Uvo5sV2+e02XxFw0F1Wf3fJiaFqW36tM4E444YQ4/fTTIyLiyCOPjFNPPTV27do18MAAAABYaLxJ4R07dsSDDz4YZ5xxxqJz09PTMT09HRERa9asicnJyf5E2Cfj4+MxOTkZ2yPasXW+7ny/veO6zvfd13X/LNOkTFm9RTHnve6Mv+l8FPW5KvY6146Pjy8431kmb+yrxqCuXq8blXrqlu8e/yqtvdGknSZrvyyuqnWat96768hrI69M03Gpo2qtF41T3r4tiz2v3e57RXccZXU13c95bVTVt9T57Nc+K1JWfyuuvHtV5/m8c4OOrZdr8+7PLcO8lza5h+WV675XlV1bVEfT53XReHar+6wchLJ7a/fx1rk69/yq+1Te56qydqpiq/rs01k+79nR5PNC1f4v+rxYdM8qepblXVd0/867vqzvneW71fk8lnddXr1lsebVU/XZoO76qzo3yurcq5bcRt2C+/bti5tuuikuu+yyWLFixaLzU1NTMTU11X4/MzPTnwj7ZHJysh1TZ2zdcZa9z3udV2eRJmXK6q0bY9P4yuKpU0fduFqLuu7Y1xmDuvq1Lpernibl65bt3BtNru11bZXNZ925Xsp+G8S9qZc92OQ+VNZm1R7tdRyq7n116lvqfA76OVJV/+zsbGW5QcW4lHqHMcaDvi6vXN69quzapfS5ybOvl/KDsJS9Wefa7jKzs7NLHuumn1mqyvdr7VfdX6vq7PWzY7+ehU2eN1XX13mG5R1vct9cjnvsIHXeq1atWjWQNmr9K5Szs7Nx0003xatf/ep45StfOZBAAAAAKFf5G7gsy+L222+PU089Nd70pjcNI6aBGrvw4tzXne+LjredtXrBz0XnK9qtKlMUx4K2c94X9a1O23ntjL3gxbXrqDOuZcfa7ydOjLFXXdDo2rp6vW5k6ume+5J6sy2beojo99fXLdOkD5VzmdO/Omup7vl+zVtZnWXruqhc91iuWLEi9lU13H3vqbFvyuIsO99+3XVPqKyvq8955YY9X03abu2honWbffd/Foz5sGLr5dolPw9qtFFLg3tYryrvTTnrsqz9oudw515YcL+tUX+/NX1O1t6HnfPVcc/JtmxaeC8omNeiescuvDiyr/5rjP35W3PLN/rM0PC6quNF9XUey3u+Vn3+Kju2aEy719Dh4wvGqnVd5z1q/Jc/i9nT/3Dx3EycGDF5UmFsrfKLrqvRj7xyZceKzi3ncyBlY1mWZWUFfvazn8VHP/rROO2002JsbCwiIt7xjnfEy1/+8tKKt23b1r8o+6DuVy8YPHMxWszHaDEfo8NcjBbzMVrMx+gwF6NlGF+hrPwN3B/+4R/Gl770pYE0DgAAQH21/g4cAAAAy08CBwAAkAgJHAAAQCIkcAAAAImQwAEAACRCAgcAAJAICRwAAEAiJHAAAACJkMABAAAkQgIHAACQCAkcAABAIiRwAAAAiZDAAQAAJEICBwAAkAgJHAAAQCIkcAAAAImQwAEAACRCAgcAAJAICRwAAEAiJHAAAACJkMABAAAkQgIHAACQCAkcAABAIiRwAAAAiZDAAQAAJEICBwAAkAgJHAAAQCIkcAAAAImQwAEAACRCAgcAAJAICRwAAEAiJHAAAACJkMABAAAkQgIHAACQCAkcAABAIiRwAAAAiZDAAQAAJEICBwAAkAgJHAAAQCIkcAAAAImQwAEAACRCAgcAAJAICRwAAEAiJHAAAACJkMABAAAkQgIHAACQCAkcAABAIiRwAAAAiZDAAQAAJEICBwAAkAgJHAAAQCIkcAAAAImQwAEAACRCAgcAAJAICRwAAEAiKhO42267Lf76r/86PvjBDw4jHg5y8+vvWu4QSNj8+rtGcg3Nrb0h5q67ojC2Ycbc2VZZu3ViapUZRPytuaxb99zaG/oeQ3c8ea9HVd35K1uTRfPbS//nrrtiYHPUz3rrrrl+rYG8cW6yr+bW3tDTfa/umJWVKzpXFE/ROppff1e7rjprrdc+59XX2W5ef+rMydzVF/cUR505aLq2i8Zkz7rPVdZZNGdN732tMt3PvLIxLJvPVrxlz9CqeAb9fBhFlQnc6173uvjIRz4yjFg4BGQb1i13CCQs27BuNNfQ1s0Rux4pjG2YMXe2VdZunZhaZQYRf2sua9e9dXPfY+iOJ+/1qKo7f2Vrsmh+e+r/rkcGN0d9rLfumuvXGsgb50b7auvm3u57dcesrFzBuaJ4itZRtmFdu65aa63XPufV19luTn9qzcm+vb3FUWcOGq7tojF54l/+ubLOojlreu9rl+l65pWNYel8tuIteYZWxjPg58MoqkzgXvjCF8bRRx89jFgAAAAoMd6viqanp2N6ejoiItasWROTk5P9qrovxsfHRy6mQ9H2MBejJqX52H7g56jFu73jdV5s2wuO51nqfHS2VdZunZhaZZrEX1fVmBXFMih54zbKe6Pu/EVBuc5z3XX1MtaD3Jv9nI+6cfZrveWNc5N91XSfdF631H1VdK4VU/d8FK2jpmut1z7XjSGvfNmcDHI/NK27bE6q7vtlY13nmdFdT9G1ddqpU19do/i5YBjPjr4lcFNTUzE1NdV+PzMz06+q+2JycnLkYjpUzc7OmosRkuLeGOV4i2KrG3M/5qPz+rK66rTTKjPIMa9b96DnvXvcRn1v9GPciua3134Parz6PR9N1n4/2yv62aSOfpfv9R6R9ywve9/LWutlDurEkHe+bE4GuR/6Na917vtLubZO+ap13a/2m9S9HDrvVatWrRpIG/4VSgAAgET07TdwUMfYhc3/NSdoGdn1c9bqiJkdMfaqC3JPDzPuzrbK2q0TU6vMIOJvXOdZq/seQ6e64zYqmsxf1bnucj31f+LEiMmTml9XRx/nvm7f+rUG8sa50b46a3WMveDFzRuuO2Zl5QrOFcVdtI7GLrw4si2bSst0t9tTn/PqO9CHzhiKYiyM51kreoojr71FGq7torE/6u2Xx76KOvOu7WXvt8tMnLjgmVc2hqX1tuLtqq+u2mN9kBnLsiwrK3DLLbfET37yk9i9e3ccd9xx8ba3vS3e8IY3VFa8bdu2vgXZD6P+VZhDibkYLeZjtJiP0WEuRov5GC3mY3SYi9EyjK9QVv4G7tprrx1IwwAAADTj78ABAAAkQgIHAACQCAkcAABAIiRwAAAAiZDAAQAAJEICBwAAkAgJHAAAQCIkcAAAAImQwAEAACRCAgcAAJAICRwAAEAiJHAAAACJkMABAAAkQgIHAACQCAkcAABAIiRwAAAAiZDAAQAAJEICBwAAkAgJHAAAQCIkcAAAAImQwAEAACRCAgcAAJAICRwAAEAiJHAAAACJkMABAAAkQgIHAACQCAkcAABAIiRwAAAAiZDAAQAAJEICBwAAkAgJHAAAQCIkcAAAAImQwAEAACRCAgcAAJAICRwAAEAiJHAAAACJkMABAAAkQgIHAACQCAkcAABAIiRwAAAAiZDAAQAAJEICBwAAkAgJHAAAQCIkcAAAAImQwAEAACRCAgcAAJAICRwAAEAiJHAAAACJkMABAAAkQgIHAACQCAkcAABAIiRwAAAAiZDAAQAAJEICBwAAkIjxOoU2btwYd9xxR8zPz8cFF1wQb3nLWwYcFgAAAN0qfwM3Pz8fn//85+MjH/lI3HzzzfHd7343fvOb3wwjtqTNr79rKHX1s51hKoq78/jc2htK68g737q+l3FJdSyHre449TKeVXPeS33mlaWaX3/XQb+OyvrYa9+bXHewj28dSxmDOvfOzvqNdzFjM3jW4tJVJnAPPPBAnHLKKXHyySfH+Ph4nH/++XHvvfcOI7akZRvWDaWufrYzTEVxLzi+dXN5JTnnW9f3Mi6pjuWw1R2nnsazas57qM+8slTZhnUH/Toq62OvfW9y3cE+vnUsaQxq3Ds76zfexYzN4FmLS1eZwO3atStWrlzZfr9y5crYtWvXQIMCAABgsVp/B66O6enpmJ6ejoiINWvWxOTkZL+q7ovx8fGhxrQ9om/tldXVz3aGZXz86WWXF3dnf6r6lne+dayXcUlxLPuh6d6oO06jMAfbD/xMaV6Hfa+iWGsuUlxHTZX1sdd92eS6OmUP9r2xlPtfnWubPF/rOFjnI8XPAqnNRb/X4qgZxnxUJnATExOxc+fO9vudO3fGxMTEonJTU1MxNTXVfj8zM9OnEPtjcnJy6DH1s72yukZtrKu0FnVR3J3Hq/qWd751rJdxSW0s+6GXvVG3/KjMQUrzuhz3KvJ1z8WhMC917sv9qK+XsofC3lhK/+pc28/1fDDPR2r9SnEuDuZ7a+d8rFq1aiBtVH6F8vnPf348/PDDsWPHjpidnY177rknzjnnnIEEAwAAQLHK38Adfvjhcfnll8eNN94Y8/Pz8frXvz6e85znDCO2pI1dePFQ6upnO8NUFPeC42etLq8k53zr+l7GJdWxHLa649TTeFbNeQ/1jb3gxf2tk0POoXBvGMRzpsl1h8IYV1nSGNS4d3bWb7yLGZvBsxaXbizLsmwQFW/btm0Q1fYsxV8vH6zMxWgxH6PFfIwOczFazMdoMR+jw1yMlpH4CiUAAACjQQIHAACQCAkcAABAIiRwAAAAiZDAAQAAJEICBwAAkAgJHAAAQCIkcAAAAImQwAEAACRCAgcAAJAICRwAAEAiJHAAAACJkMABAAAkQgIHAACQCAkcAABAIiRwAAAAiZDAAQAAJGIsy7JsuYMAAACg2iHzG7jrr79+uUPgAHMxWszHaDEfo8NcjBbzMVrMx+gwF6NlGPNxyCRwAAAAqZPAAQAAJOKQSeCmpqaWOwQOMBejxXyMFvMxOszFaDEfo8V8jA5zMVqGMR/+ERMAAIBEHDK/gQMAAEjd+HIHMGgbN26MO+64I+bn5+OCCy6It7zlLcsd0kFhZmYmbr311njsscdibGwspqam4s///M9jz549cfPNN8cjjzwSJ554Yrz//e+Po48+OrIsizvuuCN+8IMfxDOf+cy48sor4/TTT4+IiG9+85vx5S9/OSIiLrroonjd614XERG//OUv49Zbb439+/fHy172snjXu94VY2Njy9XlJMzPz8f1118fExMTcf3118eOHTvilltuid27d8fpp58eV199dYyPj8dTTz0Vn/nMZ+KXv/xlHHPMMXHttdfGSSedFBERd999d3z961+Pww47LN71rnfF2WefHRH2UlNPPPFE3H777fHQQw/F2NhYvPe9741Vq1bZH8vg3//93+PrX/96jI2NxXOe85y48sor47HHHrM3huS2226L+++/P4477ri46aabIiKG8qwoauNQlzcfd955Z9x3330xPj4eJ598clx55ZVx1FFHRUTzdd/Lc+dQljcfLRs2bIg777wzPve5z8Wxxx5rfwxY0Vz8x3/8R3zta1+Lww47LF7+8pfHO9/5zohY5r2RHcTm5uay973vfdlvf/vb7Kmnnso+9KEPZQ899NByh3VQ2LVrV/aLX/wiy7Is27t3b3bNNddkDz30UHbnnXdmd999d5ZlWXb33Xdnd955Z5ZlWXbfffdlN954YzY/P59t2bIlu+GGG7Isy7Ldu3dnV111VbZ79+4Fr7Msy66//vpsy5Yt2fz8fHbjjTdm999///A7mpgNGzZkt9xyS/aJT3wiy7Isu+mmm7LvfOc7WZZl2Wc/+9nsa1/7WpZlWfaf//mf2Wc/+9ksy7LsO9/5TvYP//APWZZl2UMPPZR96EMfyvbv359t3749e9/73pfNzc3ZSz34p3/6p2x6ejrLsix76qmnsj179tgfy2Dnzp3ZlVdemf3ud7/LsuzpPfGNb3zD3hiizZs3Z7/4xS+yD3zgA+1jw9gLRW0c6vLmY+PGjdns7GyWZU+PW2useln3TffWoS5vPrIsyx555JHs4x//ePbe9743e/zxx7Mssz8GLW8uNm3alP3d3/1dtn///izLsuyxxx7Lsmz598ZB/RXKBx54IE455ZQ4+eSTY3x8PM4///y49957lzusg8IJJ5zQ/q8+Rx55ZJx66qmxa9euuPfee+O1r31tRES89rWvbY/397///XjNa14TY2NjcdZZZ8UTTzwRjz76aGzcuDFe8pKXxNFHHx1HH310vOQlL4mNGzfGo48+Gk8++WScddZZMTY2Fq95zWvMXYWdO3fG/fffHxdccEFERGRZFps3b47zzjsvIiJe97rXLZiP1n+dO++88+LHP/5xZFkW9957b5x//vlxxBFHxEknnRSnnHJKPPDAA/ZSQ3v37o2f/vSn8YY3vCEiIsbHx+Ooo46yP5bJ/Px87N+/P+bm5mL//v1x/PHH2xtD9MIXvnDRf9kfxl4oauNQlzcfL33pS+Pwww+PiIizzjordu3aFRHReN338tw51OXNR0TEF7/4xfirv/qrBd+ssD8GK28u/uu//ive/OY3xxFHHBEREccdd1xELP/eOKi/Qrlr165YuXJl+/3KlSvj5z//+TJGdHDasWNHPPjgg3HGGWfE448/HieccEJERBx//PHx+OOPR8TTczE5Odm+ZuXKlbFr165FczQxMZF7vFWeYl/4whfine98Zzz55JMREbF79+5YsWJF+6HcGtuIhXvj8MMPjxUrVsTu3btj165dceaZZ7br7LzGXqpvx44dceyxx8Ztt90Wv/71r+P000+Pyy67zP5YBhMTE3HhhRfGe9/73njGM54RL33pS+P000+3N5bZMPZCURuU+/rXvx7nn39+RETjdd/Lc+fYY48dSr9Scu+998bExEQ897nPXXDc/hi+hx9+OH72s5/FunXr4ogjjohLL700zjjjjGXfGwf1b+AYvH379sVNN90Ul112WaxYsWLBubGxMX8nZ0juu+++OO6449q/FWV5zc3NxYMPPhh/+qd/Gp/61Kfimc98ZnzlK19ZUMb+GI49e/bEvffeG7feemt89rOfjX379sXGjRuXOyw6DGMv2G/1fPnLX47DDz88Xv3qVy93KIes3/3ud3H33XfH29/+9qG1aX8Um5+fjz179sSNN94Yl156adx8880j8ZvjgzqBm5iYiJ07d7bf79y5MyYmJpYxooPL7Oxs3HTTTfHqV786XvnKV0bE079afvTRRyMi4tFHH23/14OJiYmYmZlpX9uai+452rVrV+5xc1duy5Yt8f3vfz+uuuqquOWWW+LHP/5xfOELX4i9e/fG3NxcRPx+bCMW7o25ubnYu3dvHHPMMeajT1auXBkrV65s/9e58847Lx588EH7Yxls2rQpTjrppDj22GNjfHw8XvnKV8aWLVvsjWU2jL1Q1Ab5vvnNb8Z9990X11xzTfvDfNNxP+aYYxrvLRbavn177NixIz784Q/HVVddFTt37ozrrrsuHnvsMftjGUxMTMQrXvGKGBsbizPOOCMOO+yw2L1797LvjYM6gXv+858fDz/8cOzYsSNmZ2fjnnvuiXPOOWe5wzooZFkWt99+e5x66qnxpje9qX38nHPOiW9961sREfGtb30rzj333Pbxb3/725FlWWzdujVWrFgRJ5xwQpx99tnxwx/+MPbs2RN79uyJH/7wh3H22WfHCSecEEceeWRs3bo1siyLb3/72+auxCWXXBK333573HrrrXHttdfGi170orjmmmti9erV8b3vfS8inn44t8bwj/7oj+Kb3/xmRER873vfi9WrV8fY2Ficc845cc8998RTTz0VO3bsiIcffjjOOOMMe6mh448/PlauXBnbtm2LiKeTiGc/+9n2xzKYnJyMn//85/G73/0usixrz4W9sbyGsReK2mCxjRs3xr/927/FddddF8985jPbx5uu+7GxscZ7i4VOO+20+NznPhe33npr3HrrrbFy5cr45Cc/Gccff7z9sQzOPffc2Lx5c0REbNu2LWZnZ+OYY45Z9r1x0P+PvO+///744he/GPPz8/H6178+LrroouUO6aDws5/9LD760Y/Gaaed1l5k73jHO+LMM8+Mm2++OWZmZhb909Cf//zn44c//GE84xnPiCuvvDKe//znR8TT37e/++67I+Lpf/r29a9/fURE/OIXv4jbbrst9u/fH2effXZcfvnlbvY1bN68OTZs2BDXX399bN++PW655ZbYs2dPPO95z4urr746jjjiiNi/f3985jOfiQcffDCOPvrouPbaa+Pkk0+OiKe/QvONb3wjDjvssLjsssviZS97WUTYS0396le/ittvvz1mZ2fjpJNOiiuvvDKyLLM/lsGXvvSluOeee+Lwww+P5z73ufGe97wndu3aZW8MyS233BI/+clPYvfu3XHcccfF2972tjj33HMHvhd2796d28ahLm8+7r777pidnW2Pz5lnnhnvfve7I6L5uu/luXMoy5uP1j+AFRFx1VVXxSc+8Yn2/0bA/hicvLl4zWte0/777OPj43HppZfGi170oohY3r1x0CdwAAAAB4uD+iuUAAAABxMJHAAAQCIkcAAAAImQwAEAACRCAgcAAJAICRwAAEAiJHAAAACJkMABAAAk4v8H2pVYp/HBf9QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text4.dispersion_plot([\"citizens\", \"democracy\", \"freedom\", \"duty\", \"America\", \"nation\", \"God\", \"military\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring texts using statistics\n",
    "\n",
    "We'll explore a text by counting the frequency of different words.\n",
    "\n",
    "The total number of words (\"outcomes\") in Moby Dick is 260,819 and the number of unique words (\"samples\") is 19,317. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 19317 samples and 260819 outcomes>\n",
      "\n",
      " [(',', 18713), ('the', 13721), ('.', 6862), ('of', 6536), ('and', 6024), ('a', 4569), ('to', 4542), (';', 4072), ('in', 3916), ('that', 2982), (\"'\", 2684), ('-', 2552), ('his', 2459), ('it', 2209), ('I', 2124), ('s', 1739), ('is', 1695), ('he', 1661), ('with', 1659), ('was', 1632), ('as', 1620), ('\"', 1478), ('all', 1462), ('for', 1414), ('this', 1280), ('!', 1269), ('at', 1231), ('by', 1137), ('but', 1113), ('not', 1103), ('--', 1070), ('him', 1058), ('from', 1052), ('be', 1030), ('on', 1005), ('so', 918), ('whale', 906), ('one', 889), ('you', 841), ('had', 767), ('have', 760), ('there', 715), ('But', 705), ('or', 697), ('were', 680), ('now', 646), ('which', 640), ('?', 637), ('me', 627), ('like', 624)]\n",
      "\n",
      " 906\n"
     ]
    }
   ],
   "source": [
    "frequency_dist = FreqDist(text1)\n",
    "print(frequency_dist)\n",
    "\n",
    "# find 50 most common words\n",
    "print('\\n',frequency_dist.most_common(50))\n",
    "\n",
    "# not suprisingly, whale occurs quite frequently (906 times!)\n",
    "print('\\n', frequency_dist['whale'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find all the words in Moby Dick with more than 15 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hermaphroditical',\n",
       " 'superstitiousness',\n",
       " 'apprehensiveness',\n",
       " 'uninterpenetratingly',\n",
       " 'subterraneousness',\n",
       " 'circumnavigations',\n",
       " 'physiognomically',\n",
       " 'uncomfortableness',\n",
       " 'undiscriminating',\n",
       " 'preternaturalness',\n",
       " 'indiscriminately',\n",
       " 'circumnavigation',\n",
       " 'characteristically',\n",
       " 'circumnavigation',\n",
       " 'responsibilities',\n",
       " 'irresistibleness',\n",
       " 'indispensableness',\n",
       " 'supernaturalness',\n",
       " 'physiognomically',\n",
       " 'simultaneousness',\n",
       " 'uncompromisedness',\n",
       " 'circumnavigating',\n",
       " 'comprehensiveness',\n",
       " 'cannibalistically']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = set(text1)\n",
    "long_words = [w.lower() for w in unique_words if len(w) > 15]\n",
    "long_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopword Removal\n",
    "\n",
    "Often, it is useful to ignore frequently used words, to concentrate on the meaning of the remaining words. These are referred to as *stopwords*. Examples are \"the\", \"was\", \"is\", etc. \n",
    "\n",
    "NLTK comes with a stopword corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the task, these stopwords are important modifiers, or superfluous content. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1: Frequent Words\n",
    "Find the most frequently used words in Moby Dick that are not stopwords and not punctuation. Hint: [`str.isalpha()`](https://docs.python.org/3/library/stdtypes.html#str.isalpha) could be useful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('whale', 906), ('one', 889), ('like', 624), ('upon', 538), ('man', 508), ('ship', 507), ('Ahab', 501), ('ye', 460), ('old', 436), ('sea', 433), ('would', 421), ('head', 335), ('though', 335), ('boat', 330), ('time', 324), ('long', 318)]\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords in different corpora\n",
    "Is there a difference between the frequency in which stopwords appear in the different texts? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.5862954769399469\n",
      "2 0.5285429733853195\n",
      "3 0.5496381020462872\n",
      "4 0.5240253497361037\n",
      "5 0.7097756054210176\n",
      "6 0.7195732893263393\n",
      "7 0.697187015773372\n",
      "8 0.8255598931580028\n",
      "9 0.5608339473798275\n"
     ]
    }
   ],
   "source": [
    "def content_fraction(text):\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    content = [w for w in text if w.lower() not in stopwords]\n",
    "    return len(content) / len(text)\n",
    "\n",
    "for i,t in enumerate([text1,text2,text3,text4,text5,text6,text7,text8,text9]):\n",
    "    print(i+1,content_fraction(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, \"text8: Personals Corpus\" has the most content. Why is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 SEXY MALE , seeks attrac older single lady , for discreet encounters . 35YO Security Guard , seeking lady in uniform for fun times . 40 yo SINGLE DAD , sincere friendly DTE seeks r / ship with fem age open S / E 44yo tall seeks working single mum or lady below 45 fship rship . Nat Open 6 . 2 35 yr old OUTGOING M seeks fem 28 - 35 for o / door sports - w / e away A professional business male , late 40s , 6 feet tall , slim build , well groomed\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(text8[:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocations\n",
    "A *collocation* is a sequence of words that occur together unusually often, we can retreive these using the [`collocations()`](http://www.nltk.org/api/nltk.html#nltk.text.Text.collocations) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonel Brandon; Sir John; Lady Middleton; Miss Dashwood; every thing;\n",
      "thousand pounds; dare say; Miss Steeles; said Elinor; Miss Steele;\n",
      "every body; John Dashwood; great deal; Harley Street; Berkeley Street;\n",
      "Miss Dashwoods; young man; Combe Magna; every day; next morning\n"
     ]
    }
   ],
   "source": [
    "text2.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis for movie reviews\n",
    "When analyzing movie reviews, we can ask the simple question: Is the attitude of a movie review positive or negative? If you're developing [rotten tomatoes](https://www.rottentomatoes.com/), that's what you want to know to certify whether a review is \"fresh\" or \"rotten\".\n",
    "\n",
    "How can we approach this question?\n",
    "\n",
    "Our data is a corpus consisting of 2000 movie reviews together with the user's sentiment polarity (positive or negative). More information about this dataset is available [from this website](https://www.cs.cornell.edu/people/pabo/movie-review-data/).\n",
    "\n",
    "Our goal is to predict the sentiment polarity from just the review. \n",
    "\n",
    "Of course, this is something that we can do very easily: \n",
    "1. That movie was terrible. -> negative\n",
    "+ That movie was great! -> positive\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews as reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datset contains 1000 positive and 1000 negative movie reviews. \n",
    "\n",
    "The paths to / IDs for the individual reviews are accessible via the fileids() call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg/cv000_29416.txt',\n",
       " 'neg/cv001_19502.txt',\n",
       " 'neg/cv002_17424.txt',\n",
       " 'neg/cv003_12683.txt',\n",
       " 'neg/cv004_12641.txt']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.fileids()[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the positives or negatives explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pos/cv000_29590.txt',\n",
       " 'pos/cv001_18431.txt',\n",
       " 'pos/cv002_15918.txt',\n",
       " 'pos/cv003_11664.txt',\n",
       " 'pos/cv004_11636.txt']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.fileids('pos')[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are in fact 1000 positive and 1000 negative reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "1000 1000\n"
     ]
    }
   ],
   "source": [
    "num_reviews = len(reviews.fileids())\n",
    "print(num_reviews)\n",
    "print(len(reviews.fileids('pos')),len(reviews.fileids('neg')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the review for the third movie. Its a negative review for [The Mod Squad](https://www.rottentomatoes.com/m/mod_squad/) (see the [trailer](https://www.youtube.com/watch?v=67cdXuWnRKs)), which has a \"rotten\" rating on rotten tomatoes. \n",
    "\n",
    "![Mod Squad at Rotten Tomatoes](mod_squad.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg/cv002_17424.txt\n",
      "\n",
      " it is movies like these that make a jaded movie viewer thankful for the invention of the timex indiglo watch . \n",
      "based on the late 1960's television show by the same name , the mod squad tells the tale of three reformed criminals under the employ of the police to go undercover . \n",
      "however , things go wrong as evidence gets stolen and they are immediately under suspicion . \n",
      "of course , the ads make it seem like so much more . \n",
      "quick cuts , cool music , claire dane's nice hair and cute outfits , car chases , stuff blowing up , and the like . \n",
      "sounds like a cool movie , does it not ? \n",
      "after the first fifteen minutes , it quickly becomes apparent that it is not . \n",
      "the mod squad is certainly a slick looking production , complete with nice hair and costumes , but that simply isn't enough . \n",
      "the film is best described as a cross between an hour-long cop show and a music video , both stretched out into the span of an hour and a half . \n",
      "and with it comes every single clich ? . \n",
      "it doesn't really matter that the film is based on a television show , as most of the plot elements have been recycled from everything we've already seen . \n",
      "the characters and acting is nothing spectacular , sometimes even bordering on wooden . \n",
      "claire danes and omar epps deliver their lines as if they are bored , which really transfers onto the audience . \n",
      "the only one to escape relatively unscathed is giovanni ribisi , who plays the resident crazy man , ultimately being the only thing worth watching . \n",
      "unfortunately , even he's not enough to save this convoluted mess , as all the characters don't do much apart from occupying screen time . \n",
      "with the young cast , cool clothes , nice hair , and hip soundtrack , it appears that the film is geared towards the teenage mindset . \n",
      "despite an american 'r' rating ( which the content does not justify ) , the film is way too juvenile for the older mindset . \n",
      "information on the characters is literally spoon-fed to the audience ( would it be that hard to show us instead of telling us ? ) , dialogue is poorly written , and the plot is extremely predictable . \n",
      "the way the film progresses , you likely won't even care if the heroes are in any jeopardy , because you'll know they aren't . \n",
      "basing the show on a 1960's television show that nobody remembers is of questionable wisdom , especially when one considers the target audience and the fact that the number of memorable films based on television shows can be counted on one hand ( even one that's missing a finger or two ) . \n",
      "the number of times that i checked my watch ( six ) is a clear indication that this film is not one of them . \n",
      "it is clear that the film is nothing more than an attempt to cash in on the teenage spending dollar , judging from the rash of really awful teen-flicks that we've been seeing as of late . \n",
      "avoid this film at all costs . \n",
      "\n",
      "\n",
      " The Category: ['neg']\n",
      "\n",
      " Individual Words: ['it', 'is', 'movies', 'like', 'these', 'that', 'make', ...]\n"
     ]
    }
   ],
   "source": [
    "# the name of the file \n",
    "fid = reviews.fileids()[2]\n",
    "print(fid)\n",
    "\n",
    "print('\\n', reviews.raw(fid))\n",
    "\n",
    "\n",
    "print('\\n', \"The Category:\", reviews.categories(fid) )\n",
    "\n",
    "print('\\n', \"Individual Words:\",reviews.words(fid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some sentences that indicate that this is a negative review:\n",
    "\n",
    " * \"it is movies like these that make a jaded movie viewer thankful for the invention of the timex indiglo watch\"\n",
    " * \"sounds like a cool movie , does it not ? after the first fifteen minutes , it quickly becomes apparent that it is not .\" \n",
    " * \"nothing spectacular\"\n",
    " * \"avoid this film at all costs\"\n",
    " * \"unfortunately , even he's not enough to save this convoluted mess\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Custom Algorithm\n",
    "We'll build a sentiment classifier using methods we already know to predicts the label ['neg', 'pos'] from the review text\n",
    "\n",
    "`reviews.categories(file_id)` returns the label ['neg', 'pos'] for that movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['neg'], ['neg'], ['neg'], ['neg'], ['neg'], ['neg'], ['neg'], ['neg'], ['neg'], ['neg']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = [reviews.categories(fid) for fid in reviews.fileids()]\n",
    "print(categories[0:10])\n",
    "labels = {'pos':1, 'neg':0}\n",
    "# create the labels: 1 for positive, 0 for negative\n",
    "y = [labels[x[0]] for x in categories]\n",
    "# output labels for the first (a negative) and the 1000th (a positive review)\n",
    "y[0], y[1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we collect all words into a nested array datastructure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_words = [list(reviews.words(fid)) for fid in reviews.fileids()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is', 'movies', 'like', 'these', 'that', 'make', 'a', 'jaded', 'movie']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 10 words of the third document - mod squad\n",
    "doc_words[2][1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we get all of the words in the reviews and make a FreqDist, pick the most common 2000 words and remove the stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('film', 9517),\n",
       " ('one', 5852),\n",
       " ('movie', 5771),\n",
       " ('like', 3690),\n",
       " ('even', 2565),\n",
       " ('good', 2411),\n",
       " ('time', 2411),\n",
       " ('story', 2169),\n",
       " ('would', 2109),\n",
       " ('much', 2049),\n",
       " ('character', 2020),\n",
       " ('also', 1967),\n",
       " ('get', 1949),\n",
       " ('two', 1911),\n",
       " ('well', 1906),\n",
       " ('characters', 1859),\n",
       " ('first', 1836),\n",
       " ('see', 1749),\n",
       " ('way', 1693),\n",
       " ('make', 1642),\n",
       " ('life', 1586),\n",
       " ('really', 1558),\n",
       " ('films', 1536),\n",
       " ('plot', 1513),\n",
       " ('little', 1501),\n",
       " ('people', 1455),\n",
       " ('could', 1427),\n",
       " ('scene', 1397),\n",
       " ('man', 1396),\n",
       " ('bad', 1395),\n",
       " ('never', 1374),\n",
       " ('best', 1333),\n",
       " ('new', 1292),\n",
       " ('scenes', 1274),\n",
       " ('many', 1268),\n",
       " ('director', 1237),\n",
       " ('know', 1217),\n",
       " ('movies', 1206),\n",
       " ('action', 1172),\n",
       " ('great', 1148),\n",
       " ('another', 1121),\n",
       " ('love', 1119),\n",
       " ('go', 1113),\n",
       " ('made', 1084),\n",
       " ('us', 1073),\n",
       " ('big', 1064),\n",
       " ('end', 1062),\n",
       " ('something', 1061),\n",
       " ('back', 1060),\n",
       " ('still', 1047)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the 2000 most common words in lowercase\n",
    "most_common = nltk.FreqDist(w.lower() for w in reviews.words()).most_common(2000)\n",
    "\n",
    "# remove stopwords\n",
    "filtered_words = [word_tuple for word_tuple in most_common if word_tuple[0].lower() not in stopwords]\n",
    "# remove punctuation marks\n",
    "filtered_words = [word_tuple for word_tuple in filtered_words if word_tuple[0].isalpha()]\n",
    "print(len(filtered_words))\n",
    "filtered_words[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We  extract this word list from the frequency tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['film', 'one', 'movie', 'like', 'even']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1821"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_features =  [word_tuple[0] for word_tuple in filtered_words]\n",
    "print(word_features[:5])\n",
    "len(word_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function that takes a document and returns a list of zeros and ones indicating which of the words in  `word_features` appears in that document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(document):\n",
    "    # convert each document into a set of its words \n",
    "    # this removes duplicates and makes \"existence\" tests efficient\n",
    "    document_words = set(document)\n",
    "    # a list, initalized with 0s, that we'll set to 1 for each of the words that exists in the document\n",
    "    features = np.zeros(len(word_features))\n",
    "    for i, word in enumerate(word_features):\n",
    "        features[i] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just focus on the third document. Which words from `word_features` are in this document? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 0. 0. 0.]\n",
      "\n",
      " ['film', 'one', 'movie', 'like', 'even', 'time', 'would', 'much', 'two', 'characters', 'first', 'way', 'make', 'really', 'films', 'plot', 'man', 'best', 'know', 'movies', 'go', 'us', 'however', 'every', 'audience', 'enough', 'seen', 'gets', 'things', 'long', 'thing', 'fact', 'nothing', 'cast', 'plays', 'young', 'show', 'comes', 'screen', 'acting', 'three', 'course', 'minutes', 'watch', 'hard', 'seem', 'times', 'instead', 'american', 'half', 'everything', 'becomes', 'dialogue', 'looking', 'watching', 'music', 'especially', 'simply', 'shows', 'written', 'name', 'based', 'wrong', 'unfortunately', 'hand', 'certainly', 'hour', 'despite', 'nice', 'seeing', 'video', 'car', 'matter', 'lines', 'worth', 'care', 'production', 'already', 'sometimes', 'save', 'attempt', 'tells', 'quickly', 'extremely', 'appears', 'police', 'single', 'late', 'elements', 'number', 'television', 'viewer', 'tale', 'cool', 'stuff', 'cop', 'complete', 'clear', 'towards', 'predictable', 'r', 'likely', 'immediately', 'mess', 'escape', 'ultimately', 'teen', 'rating', 'soundtrack', 'memorable', 'six', 'quick', 'cute', 'sounds', 'telling', 'awful', 'onto', 'apart', 'missing', 'cross', 'hair', 'literally', 'teenage', 'older', 'heroes', 'apparent', 'information', 'crazy', 'poorly', 'target', 'deliver', 'cash', 'avoid', 'nobody', 'spectacular', 'bored', 'flicks', 'content', 'clich', 'costumes', 'claire']\n"
     ]
    }
   ],
   "source": [
    "words_in_doc_2 = document_features(doc_words[2])\n",
    "print(words_in_doc_2)\n",
    "\n",
    "inds = np.where(words_in_doc_2 == 1)[0]\n",
    "print('\\n', [word_features[i] for i in inds])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build our feature set for all the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.zeros([num_reviews,len(word_features)])\n",
    "for i in range(num_reviews):\n",
    "    X[i,:] = document_features(doc_words[i])\n",
    "\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a feature vector for each of these reviews that we can use in classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have features for each document and labels, **we have a classification problem!** \n",
    "\n",
    "NLTK has a built-in classifier, but we'll use the scikit-learn classifiers we're already familiar with. \n",
    "\n",
    "Let's try k-nearest neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.595 0.635 0.54  0.625 0.615 0.585 0.61  0.685 0.615 0.635]\n"
     ]
    }
   ],
   "source": [
    "k = 30\n",
    "model = KNeighborsClassifier(n_neighbors=k)\n",
    "scores = cross_val_score(model, X, y, cv=10)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78  0.83  0.855 0.815 0.825 0.85  0.835 0.84  0.79  0.86 ]\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC(kernel='rbf', C=30, gamma=\"auto\")\n",
    "scores = cross_val_score(model, X, y, cv=10)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that kNN with these parameters is less accurate than SVM, which is about 80% accurate. Of course, we could now use cross validation to find the optimal parameters, `k` and `C`, but as always, SVM is slow... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's see what our algorithm things about the Mod Squad! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=30, gamma=&#x27;auto&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=30, gamma=&#x27;auto&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=30, gamma='auto')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain, XTest, yTrain, yTest = train_test_split(X, y, random_state=1, test_size=0.2)\n",
    "\n",
    "model.fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1., 1., 1., ..., 0., 0., 0.])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_squad = [X[2]]\n",
    "mod_squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(mod_squad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model says 0 - so a bad review! We have succesfully build a classifier that can detect the Mod Squad review as a bad review! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a mis-classified movie. Remember, that the first 1000 movies are negative reviews, so we can just look for the first negative one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review 9, which was misclassified, is for Aberdeen, which has [generally favorable reviews](https://www.rottentomatoes.com/m/aberdeen/) with about 80% positive. Let's looks at the review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " call it a road trip for the walking wounded . \n",
      "stellan skarsg ? rd plays such a convincingly zombified drunken loser that it's difficult to spend nearly two hours of screen time in his smelly , boozed-out presence . \n",
      "yet this ever-reliable swedish actor adds depth and significance to the otherwise plodding and forgettable aberdeen , a sentimental and painfully mundane european drama . \n",
      "playwright august strindberg built his career on families and relationships paralyzed by secrets , unable to express their longings until the hour is far too late . \n",
      "that's an accurate reflection of what aberdeen strives for , focusing on the pairing of an alcoholic father , tomas ( skarsg ? rd ) and his alienated , openly hostile yuppie daughter , kaisa ( lena headey , gossip ) . \n",
      "they haven't spoken in years , and wouldn't even be making the long trip from norway to aberdeen , scotland by automobile if it weren't for kaisa's mother ( charlotte rampling , under the sand ) rotting away in a hospital bed from cancer . \n",
      "in a soap opera twist , mother has only a few days to live . \n",
      " ( only in the movies , right ? ) \n",
      "too blitzed to even step foot on a plane , tomas hits the open road with kaisa . \n",
      "loathing each other all the while , they make periodic stops for tomas to puke on the dashboard or pass out -- whenever he isn't muttering what a rotten kid she turned out to be . \n",
      "despite his sloshed viewpoint , tomas recognizes that the apple hasn't fallen very far from the tree . \n",
      "kaisa gets nosebleeds from snorting coke , sabotages her personal relationships through indifference , and is unable to restrain her quick and vindictive temper . \n",
      "ain't they a pair ? \n",
      "unable to find true notes of unspoken familial empathy in the one-note and repetitively bitchy dialogue , screenwriters kristin amundsen and hans petter moland fabricate a series of contrivances to propel events forward -- lost money , roving street hooligans looking for drunks to kick around , nosy cops , and flat tires all figure into the schematic and convenient narrative . \n",
      "by the time they reach the hospital , it's time to unveil the secrets from a dark past that are not only simplistic devices that trivialize the father-daughter conflict , they're also the mainstays of many a bad strindberg wannabe . \n",
      "this revelation exists purely for its own sake . \n",
      "aberdeen doesn't know where else to go . \n",
      "weak , unimaginative casting thwarts the pivotal role of kaisa . \n",
      "if lena headey were a stronger actress , perhaps aberdeen could have been able to coast on the performances and moody , haunting cinematography ( rendering norway into its own pastoral ghost world -- the reference to a certain superior american indie flick intentional ) . \n",
      "headey's too busy acting , using her face and furrowed brow to convey every last twitch of insouciance . \n",
      "if she were paying any attention to skarsg ? rd , maybe she'd figure out that doing less can reveal so much more . \n",
      "it's worthwhile to compare aberdeen to an earlier film released in 2001 , jonathan nossiter's captivating signs & wonders . \n",
      "it's not just because skarsg ? rd and rampling played disturbed parental figures in both films ( they're not bound by ceremonial wedlock in aberdeen ) . \n",
      "the differences in the way their characters were presented is significant . \n",
      "in aberdeen , rampling is a luminous diva , preening and static in her hospital bed . \n",
      "despite skarsg ? rd's solid performance as tomas , his pathetic drunk is never given much of a chance to emote anything besides catatonic sorrow . \n",
      "there's genuine ferocity and sexually charged frisson during their understated confrontations in signs & wonders , allowing them to suggest a gray zone of complications that accompany torn romance and years of stifled curiosity . \n",
      "nossiter's film thoroughly explores this neurotic territory in addition to delving into the americanization of greece and the use of mysticism as an illusion to deflect pain . \n",
      "if signs & wonders sometimes feels overloaded with ideas , at least it's willing to stretch beyond what we've come to expect from traditional drama . \n",
      "aberdeen is never half so ambitious , content to sleepwalk through the rhythms and timing of other movies . \n",
      "when did character driven stories stop paying attention to the complexities of real life ? \n",
      "the depressing answer can be found in lawrence kasdan's trite but occasionally useful grand canyon , where steve martin's hollywood mogul pronounces , \" all of life's riddles are answered in the movies ! \" \n",
      "even foreign films are taking that advice to heart . \n",
      "\n",
      "\n",
      " ['neg']\n"
     ]
    }
   ],
   "source": [
    "fid = reviews.fileids()[8]\n",
    "\n",
    "print('\\n', reviews.raw(fid))\n",
    "print('\\n', reviews.categories(fid) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if we read this, we can see that this is a negative review, but not a terrible review. Take this sentence for example: \n",
    "\n",
    " * \"if signs & wonders sometimes feels overloaded with ideas , at least it's willing to stretch beyond what we've come to expect from traditional drama\"\n",
    " * \"yet this ever-reliable swedish actor adds depth and significance to the otherwise plodding and forgettable aberdeen , a sentimental and painfully mundane european drama\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We could have also used the Classifier from the NLTK library\n",
    "\n",
    "Below is the sentiment analysis from [Ch. 6 of the NLTK book](http://www.nltk.org/book/ch06.html). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [(list(reviews.words(fileid)), category)\n",
    "             for category in reviews.categories() \n",
    "             for fileid in reviews.fileids(category)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This list contains tuples where the review, stored as an array of words, is the first item in the tuple and the category is the second. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['the',\n",
       "  'happy',\n",
       "  'bastard',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'quick',\n",
       "  'movie',\n",
       "  'review',\n",
       "  'damn',\n",
       "  'that',\n",
       "  'y2k',\n",
       "  'bug',\n",
       "  '.',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'got',\n",
       "  'a',\n",
       "  'head',\n",
       "  'start',\n",
       "  'in',\n",
       "  'this',\n",
       "  'movie',\n",
       "  'starring',\n",
       "  'jamie',\n",
       "  'lee',\n",
       "  'curtis',\n",
       "  'and',\n",
       "  'another',\n",
       "  'baldwin',\n",
       "  'brother',\n",
       "  '(',\n",
       "  'william',\n",
       "  'this',\n",
       "  'time',\n",
       "  ')',\n",
       "  'in',\n",
       "  'a',\n",
       "  'story',\n",
       "  'regarding',\n",
       "  'a',\n",
       "  'crew',\n",
       "  'of',\n",
       "  'a',\n",
       "  'tugboat',\n",
       "  'that',\n",
       "  'comes',\n",
       "  'across',\n",
       "  'a',\n",
       "  'deserted',\n",
       "  'russian',\n",
       "  'tech',\n",
       "  'ship',\n",
       "  'that',\n",
       "  'has',\n",
       "  'a',\n",
       "  'strangeness',\n",
       "  'to',\n",
       "  'it',\n",
       "  'when',\n",
       "  'they',\n",
       "  'kick',\n",
       "  'the',\n",
       "  'power',\n",
       "  'back',\n",
       "  'on',\n",
       "  '.',\n",
       "  'little',\n",
       "  'do',\n",
       "  'they',\n",
       "  'know',\n",
       "  'the',\n",
       "  'power',\n",
       "  'within',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  'going',\n",
       "  'for',\n",
       "  'the',\n",
       "  'gore',\n",
       "  'and',\n",
       "  'bringing',\n",
       "  'on',\n",
       "  'a',\n",
       "  'few',\n",
       "  'action',\n",
       "  'sequences',\n",
       "  'here',\n",
       "  'and',\n",
       "  'there',\n",
       "  ',',\n",
       "  'virus',\n",
       "  'still',\n",
       "  'feels',\n",
       "  'very',\n",
       "  'empty',\n",
       "  ',',\n",
       "  'like',\n",
       "  'a',\n",
       "  'movie',\n",
       "  'going',\n",
       "  'for',\n",
       "  'all',\n",
       "  'flash',\n",
       "  'and',\n",
       "  'no',\n",
       "  'substance',\n",
       "  '.',\n",
       "  'we',\n",
       "  'don',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'know',\n",
       "  'why',\n",
       "  'the',\n",
       "  'crew',\n",
       "  'was',\n",
       "  'really',\n",
       "  'out',\n",
       "  'in',\n",
       "  'the',\n",
       "  'middle',\n",
       "  'of',\n",
       "  'nowhere',\n",
       "  ',',\n",
       "  'we',\n",
       "  'don',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'know',\n",
       "  'the',\n",
       "  'origin',\n",
       "  'of',\n",
       "  'what',\n",
       "  'took',\n",
       "  'over',\n",
       "  'the',\n",
       "  'ship',\n",
       "  '(',\n",
       "  'just',\n",
       "  'that',\n",
       "  'a',\n",
       "  'big',\n",
       "  'pink',\n",
       "  'flashy',\n",
       "  'thing',\n",
       "  'hit',\n",
       "  'the',\n",
       "  'mir',\n",
       "  ')',\n",
       "  ',',\n",
       "  'and',\n",
       "  ',',\n",
       "  'of',\n",
       "  'course',\n",
       "  ',',\n",
       "  'we',\n",
       "  'don',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'know',\n",
       "  'why',\n",
       "  'donald',\n",
       "  'sutherland',\n",
       "  'is',\n",
       "  'stumbling',\n",
       "  'around',\n",
       "  'drunkenly',\n",
       "  'throughout',\n",
       "  '.',\n",
       "  'here',\n",
       "  ',',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'just',\n",
       "  '\"',\n",
       "  'hey',\n",
       "  ',',\n",
       "  'let',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'chase',\n",
       "  'these',\n",
       "  'people',\n",
       "  'around',\n",
       "  'with',\n",
       "  'some',\n",
       "  'robots',\n",
       "  '\"',\n",
       "  '.',\n",
       "  'the',\n",
       "  'acting',\n",
       "  'is',\n",
       "  'below',\n",
       "  'average',\n",
       "  ',',\n",
       "  'even',\n",
       "  'from',\n",
       "  'the',\n",
       "  'likes',\n",
       "  'of',\n",
       "  'curtis',\n",
       "  '.',\n",
       "  'you',\n",
       "  \"'\",\n",
       "  're',\n",
       "  'more',\n",
       "  'likely',\n",
       "  'to',\n",
       "  'get',\n",
       "  'a',\n",
       "  'kick',\n",
       "  'out',\n",
       "  'of',\n",
       "  'her',\n",
       "  'work',\n",
       "  'in',\n",
       "  'halloween',\n",
       "  'h20',\n",
       "  '.',\n",
       "  'sutherland',\n",
       "  'is',\n",
       "  'wasted',\n",
       "  'and',\n",
       "  'baldwin',\n",
       "  ',',\n",
       "  'well',\n",
       "  ',',\n",
       "  'he',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'acting',\n",
       "  'like',\n",
       "  'a',\n",
       "  'baldwin',\n",
       "  ',',\n",
       "  'of',\n",
       "  'course',\n",
       "  '.',\n",
       "  'the',\n",
       "  'real',\n",
       "  'star',\n",
       "  'here',\n",
       "  'are',\n",
       "  'stan',\n",
       "  'winston',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'robot',\n",
       "  'design',\n",
       "  ',',\n",
       "  'some',\n",
       "  'schnazzy',\n",
       "  'cgi',\n",
       "  ',',\n",
       "  'and',\n",
       "  'the',\n",
       "  'occasional',\n",
       "  'good',\n",
       "  'gore',\n",
       "  'shot',\n",
       "  ',',\n",
       "  'like',\n",
       "  'picking',\n",
       "  'into',\n",
       "  'someone',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'brain',\n",
       "  '.',\n",
       "  'so',\n",
       "  ',',\n",
       "  'if',\n",
       "  'robots',\n",
       "  'and',\n",
       "  'body',\n",
       "  'parts',\n",
       "  'really',\n",
       "  'turn',\n",
       "  'you',\n",
       "  'on',\n",
       "  ',',\n",
       "  'here',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'your',\n",
       "  'movie',\n",
       "  '.',\n",
       "  'otherwise',\n",
       "  ',',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'pretty',\n",
       "  'much',\n",
       "  'a',\n",
       "  'sunken',\n",
       "  'ship',\n",
       "  'of',\n",
       "  'a',\n",
       "  'movie',\n",
       "  '.'],\n",
       " 'neg')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the features from all of the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(document):    \n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains('+ word +')'] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "featuresets = [(document_features(d), c) for (d,c) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'contains(film)': True,\n",
       "  'contains(one)': True,\n",
       "  'contains(movie)': True,\n",
       "  'contains(like)': True,\n",
       "  'contains(even)': True,\n",
       "  'contains(good)': False,\n",
       "  'contains(time)': True,\n",
       "  'contains(story)': False,\n",
       "  'contains(would)': True,\n",
       "  'contains(much)': True,\n",
       "  'contains(character)': False,\n",
       "  'contains(also)': False,\n",
       "  'contains(get)': False,\n",
       "  'contains(two)': True,\n",
       "  'contains(well)': False,\n",
       "  'contains(characters)': True,\n",
       "  'contains(first)': True,\n",
       "  'contains(see)': False,\n",
       "  'contains(way)': True,\n",
       "  'contains(make)': True,\n",
       "  'contains(life)': False,\n",
       "  'contains(really)': True,\n",
       "  'contains(films)': True,\n",
       "  'contains(plot)': True,\n",
       "  'contains(little)': False,\n",
       "  'contains(people)': False,\n",
       "  'contains(could)': False,\n",
       "  'contains(scene)': False,\n",
       "  'contains(man)': True,\n",
       "  'contains(bad)': False,\n",
       "  'contains(never)': False,\n",
       "  'contains(best)': True,\n",
       "  'contains(new)': False,\n",
       "  'contains(scenes)': False,\n",
       "  'contains(many)': False,\n",
       "  'contains(director)': False,\n",
       "  'contains(know)': True,\n",
       "  'contains(movies)': True,\n",
       "  'contains(action)': False,\n",
       "  'contains(great)': False,\n",
       "  'contains(another)': False,\n",
       "  'contains(love)': False,\n",
       "  'contains(go)': True,\n",
       "  'contains(made)': False,\n",
       "  'contains(us)': True,\n",
       "  'contains(big)': False,\n",
       "  'contains(end)': False,\n",
       "  'contains(something)': False,\n",
       "  'contains(back)': False,\n",
       "  'contains(still)': False,\n",
       "  'contains(world)': False,\n",
       "  'contains(seems)': False,\n",
       "  'contains(work)': False,\n",
       "  'contains(makes)': False,\n",
       "  'contains(however)': True,\n",
       "  'contains(every)': True,\n",
       "  'contains(though)': False,\n",
       "  'contains(better)': False,\n",
       "  'contains(real)': False,\n",
       "  'contains(audience)': True,\n",
       "  'contains(enough)': True,\n",
       "  'contains(seen)': True,\n",
       "  'contains(take)': False,\n",
       "  'contains(around)': False,\n",
       "  'contains(going)': False,\n",
       "  'contains(year)': False,\n",
       "  'contains(performance)': False,\n",
       "  'contains(role)': False,\n",
       "  'contains(old)': False,\n",
       "  'contains(gets)': True,\n",
       "  'contains(may)': False,\n",
       "  'contains(things)': True,\n",
       "  'contains(think)': False,\n",
       "  'contains(years)': False,\n",
       "  'contains(last)': False,\n",
       "  'contains(comedy)': False,\n",
       "  'contains(funny)': False,\n",
       "  'contains(actually)': False,\n",
       "  'contains(long)': True,\n",
       "  'contains(look)': False,\n",
       "  'contains(almost)': False,\n",
       "  'contains(thing)': True,\n",
       "  'contains(fact)': True,\n",
       "  'contains(nothing)': True,\n",
       "  'contains(say)': False,\n",
       "  'contains(right)': False,\n",
       "  'contains(john)': False,\n",
       "  'contains(although)': False,\n",
       "  'contains(played)': False,\n",
       "  'contains(find)': False,\n",
       "  'contains(script)': False,\n",
       "  'contains(come)': False,\n",
       "  'contains(ever)': False,\n",
       "  'contains(cast)': True,\n",
       "  'contains(since)': False,\n",
       "  'contains(star)': False,\n",
       "  'contains(plays)': True,\n",
       "  'contains(young)': True,\n",
       "  'contains(show)': True,\n",
       "  'contains(comes)': True,\n",
       "  'contains(part)': False,\n",
       "  'contains(original)': False,\n",
       "  'contains(actors)': False,\n",
       "  'contains(screen)': True,\n",
       "  'contains(without)': False,\n",
       "  'contains(acting)': True,\n",
       "  'contains(three)': True,\n",
       "  'contains(day)': False,\n",
       "  'contains(point)': False,\n",
       "  'contains(lot)': False,\n",
       "  'contains(least)': False,\n",
       "  'contains(takes)': False,\n",
       "  'contains(guy)': False,\n",
       "  'contains(quite)': False,\n",
       "  'contains(away)': False,\n",
       "  'contains(family)': False,\n",
       "  'contains(effects)': False,\n",
       "  'contains(course)': True,\n",
       "  'contains(goes)': False,\n",
       "  'contains(minutes)': True,\n",
       "  'contains(interesting)': False,\n",
       "  'contains(might)': False,\n",
       "  'contains(far)': False,\n",
       "  'contains(high)': False,\n",
       "  'contains(rather)': False,\n",
       "  'contains(must)': False,\n",
       "  'contains(anything)': False,\n",
       "  'contains(place)': False,\n",
       "  'contains(set)': False,\n",
       "  'contains(yet)': False,\n",
       "  'contains(watch)': True,\n",
       "  'contains(making)': False,\n",
       "  'contains(wife)': False,\n",
       "  'contains(hard)': True,\n",
       "  'contains(always)': False,\n",
       "  'contains(fun)': False,\n",
       "  'contains(seem)': True,\n",
       "  'contains(special)': False,\n",
       "  'contains(bit)': False,\n",
       "  'contains(times)': True,\n",
       "  'contains(trying)': False,\n",
       "  'contains(hollywood)': False,\n",
       "  'contains(instead)': True,\n",
       "  'contains(give)': False,\n",
       "  'contains(want)': False,\n",
       "  'contains(picture)': False,\n",
       "  'contains(kind)': False,\n",
       "  'contains(american)': True,\n",
       "  'contains(job)': False,\n",
       "  'contains(sense)': False,\n",
       "  'contains(woman)': False,\n",
       "  'contains(home)': False,\n",
       "  'contains(series)': False,\n",
       "  'contains(actor)': False,\n",
       "  'contains(probably)': False,\n",
       "  'contains(help)': False,\n",
       "  'contains(half)': True,\n",
       "  'contains(along)': False,\n",
       "  'contains(men)': False,\n",
       "  'contains(everything)': True,\n",
       "  'contains(pretty)': False,\n",
       "  'contains(becomes)': True,\n",
       "  'contains(sure)': False,\n",
       "  'contains(black)': False,\n",
       "  'contains(together)': False,\n",
       "  'contains(dialogue)': True,\n",
       "  'contains(money)': False,\n",
       "  'contains(become)': False,\n",
       "  'contains(gives)': False,\n",
       "  'contains(given)': False,\n",
       "  'contains(looking)': True,\n",
       "  'contains(whole)': False,\n",
       "  'contains(watching)': True,\n",
       "  'contains(father)': False,\n",
       "  'contains(feel)': False,\n",
       "  'contains(everyone)': False,\n",
       "  'contains(music)': True,\n",
       "  'contains(wants)': False,\n",
       "  'contains(sex)': False,\n",
       "  'contains(less)': False,\n",
       "  'contains(done)': False,\n",
       "  'contains(horror)': False,\n",
       "  'contains(got)': False,\n",
       "  'contains(death)': False,\n",
       "  'contains(perhaps)': False,\n",
       "  'contains(city)': False,\n",
       "  'contains(next)': False,\n",
       "  'contains(especially)': True,\n",
       "  'contains(play)': False,\n",
       "  'contains(girl)': False,\n",
       "  'contains(mind)': False,\n",
       "  'contains(moments)': False,\n",
       "  'contains(looks)': False,\n",
       "  'contains(completely)': False,\n",
       "  'contains(reason)': False,\n",
       "  'contains(mother)': False,\n",
       "  'contains(whose)': False,\n",
       "  'contains(line)': False,\n",
       "  'contains(night)': False,\n",
       "  'contains(human)': False,\n",
       "  'contains(rest)': False,\n",
       "  'contains(performances)': False,\n",
       "  'contains(different)': False,\n",
       "  'contains(evil)': False,\n",
       "  'contains(small)': False,\n",
       "  'contains(james)': False,\n",
       "  'contains(simply)': True,\n",
       "  'contains(couple)': False,\n",
       "  'contains(put)': False,\n",
       "  'contains(let)': False,\n",
       "  'contains(anyone)': False,\n",
       "  'contains(ending)': False,\n",
       "  'contains(case)': False,\n",
       "  'contains(several)': False,\n",
       "  'contains(dead)': False,\n",
       "  'contains(michael)': False,\n",
       "  'contains(left)': False,\n",
       "  'contains(thought)': False,\n",
       "  'contains(school)': False,\n",
       "  'contains(shows)': True,\n",
       "  'contains(humor)': False,\n",
       "  'contains(true)': False,\n",
       "  'contains(lost)': False,\n",
       "  'contains(written)': True,\n",
       "  'contains(friend)': False,\n",
       "  'contains(entire)': False,\n",
       "  'contains(getting)': False,\n",
       "  'contains(town)': False,\n",
       "  'contains(turns)': False,\n",
       "  'contains(soon)': False,\n",
       "  'contains(someone)': False,\n",
       "  'contains(second)': False,\n",
       "  'contains(main)': False,\n",
       "  'contains(stars)': False,\n",
       "  'contains(found)': False,\n",
       "  'contains(use)': False,\n",
       "  'contains(problem)': False,\n",
       "  'contains(friends)': False,\n",
       "  'contains(tv)': False,\n",
       "  'contains(top)': False,\n",
       "  'contains(name)': True,\n",
       "  'contains(begins)': False,\n",
       "  'contains(called)': False,\n",
       "  'contains(based)': True,\n",
       "  'contains(comic)': False,\n",
       "  'contains(david)': False,\n",
       "  'contains(head)': False,\n",
       "  'contains(else)': False,\n",
       "  'contains(idea)': False,\n",
       "  'contains(either)': False,\n",
       "  'contains(wrong)': True,\n",
       "  'contains(unfortunately)': True,\n",
       "  'contains(later)': False,\n",
       "  'contains(final)': False,\n",
       "  'contains(hand)': True,\n",
       "  'contains(alien)': False,\n",
       "  'contains(house)': False,\n",
       "  'contains(group)': False,\n",
       "  'contains(full)': False,\n",
       "  'contains(used)': False,\n",
       "  'contains(tries)': False,\n",
       "  'contains(often)': False,\n",
       "  'contains(war)': False,\n",
       "  'contains(sequence)': False,\n",
       "  'contains(keep)': False,\n",
       "  'contains(turn)': False,\n",
       "  'contains(playing)': False,\n",
       "  'contains(boy)': False,\n",
       "  'contains(behind)': False,\n",
       "  'contains(named)': False,\n",
       "  'contains(certainly)': True,\n",
       "  'contains(live)': False,\n",
       "  'contains(believe)': False,\n",
       "  'contains(works)': False,\n",
       "  'contains(relationship)': False,\n",
       "  'contains(face)': False,\n",
       "  'contains(hour)': True,\n",
       "  'contains(run)': False,\n",
       "  'contains(style)': False,\n",
       "  'contains(said)': False,\n",
       "  'contains(despite)': True,\n",
       "  'contains(person)': False,\n",
       "  'contains(finally)': False,\n",
       "  'contains(shot)': False,\n",
       "  'contains(book)': False,\n",
       "  'contains(tell)': False,\n",
       "  'contains(maybe)': False,\n",
       "  'contains(nice)': True,\n",
       "  'contains(son)': False,\n",
       "  'contains(perfect)': False,\n",
       "  'contains(side)': False,\n",
       "  'contains(seeing)': True,\n",
       "  'contains(able)': False,\n",
       "  'contains(finds)': False,\n",
       "  'contains(children)': False,\n",
       "  'contains(days)': False,\n",
       "  'contains(past)': False,\n",
       "  'contains(summer)': False,\n",
       "  'contains(camera)': False,\n",
       "  'contains(including)': False,\n",
       "  'contains(mr)': False,\n",
       "  'contains(kids)': False,\n",
       "  'contains(lives)': False,\n",
       "  'contains(directed)': False,\n",
       "  'contains(moment)': False,\n",
       "  'contains(game)': False,\n",
       "  'contains(running)': False,\n",
       "  'contains(fight)': False,\n",
       "  'contains(supposed)': False,\n",
       "  'contains(video)': True,\n",
       "  'contains(car)': True,\n",
       "  'contains(matter)': True,\n",
       "  'contains(kevin)': False,\n",
       "  'contains(joe)': False,\n",
       "  'contains(lines)': True,\n",
       "  'contains(worth)': True,\n",
       "  'contains(daughter)': False,\n",
       "  'contains(earth)': False,\n",
       "  'contains(starts)': False,\n",
       "  'contains(need)': False,\n",
       "  'contains(entertaining)': False,\n",
       "  'contains(white)': False,\n",
       "  'contains(start)': False,\n",
       "  'contains(writer)': False,\n",
       "  'contains(dark)': False,\n",
       "  'contains(short)': False,\n",
       "  'contains(self)': False,\n",
       "  'contains(worst)': False,\n",
       "  'contains(nearly)': False,\n",
       "  'contains(opening)': False,\n",
       "  'contains(try)': False,\n",
       "  'contains(upon)': False,\n",
       "  'contains(care)': True,\n",
       "  'contains(early)': False,\n",
       "  'contains(violence)': False,\n",
       "  'contains(throughout)': False,\n",
       "  'contains(team)': False,\n",
       "  'contains(production)': True,\n",
       "  'contains(example)': False,\n",
       "  'contains(beautiful)': False,\n",
       "  'contains(title)': False,\n",
       "  'contains(exactly)': False,\n",
       "  'contains(jack)': False,\n",
       "  'contains(review)': False,\n",
       "  'contains(major)': False,\n",
       "  'contains(drama)': False,\n",
       "  'contains(problems)': False,\n",
       "  'contains(sequences)': False,\n",
       "  'contains(obvious)': False,\n",
       "  'contains(version)': False,\n",
       "  'contains(screenplay)': False,\n",
       "  'contains(known)': False,\n",
       "  'contains(killer)': False,\n",
       "  'contains(robert)': False,\n",
       "  'contains(disney)': False,\n",
       "  'contains(already)': True,\n",
       "  'contains(close)': False,\n",
       "  'contains(classic)': False,\n",
       "  'contains(others)': False,\n",
       "  'contains(hit)': False,\n",
       "  'contains(kill)': False,\n",
       "  'contains(deep)': False,\n",
       "  'contains(five)': False,\n",
       "  'contains(order)': False,\n",
       "  'contains(act)': False,\n",
       "  'contains(simple)': False,\n",
       "  'contains(fine)': False,\n",
       "  'contains(heart)': False,\n",
       "  'contains(roles)': False,\n",
       "  'contains(jackie)': False,\n",
       "  'contains(direction)': False,\n",
       "  'contains(eyes)': False,\n",
       "  'contains(four)': False,\n",
       "  'contains(question)': False,\n",
       "  'contains(sort)': False,\n",
       "  'contains(sometimes)': True,\n",
       "  'contains(knows)': False,\n",
       "  'contains(supporting)': False,\n",
       "  'contains(coming)': False,\n",
       "  'contains(voice)': False,\n",
       "  'contains(women)': False,\n",
       "  'contains(truly)': False,\n",
       "  'contains(save)': True,\n",
       "  'contains(jokes)': False,\n",
       "  'contains(computer)': False,\n",
       "  'contains(child)': False,\n",
       "  'contains(boring)': False,\n",
       "  'contains(tom)': False,\n",
       "  'contains(level)': False,\n",
       "  'contains(body)': False,\n",
       "  'contains(guys)': False,\n",
       "  'contains(genre)': False,\n",
       "  'contains(brother)': False,\n",
       "  'contains(strong)': False,\n",
       "  'contains(stop)': False,\n",
       "  'contains(room)': False,\n",
       "  'contains(space)': False,\n",
       "  'contains(lee)': False,\n",
       "  'contains(ends)': False,\n",
       "  'contains(beginning)': False,\n",
       "  'contains(ship)': False,\n",
       "  'contains(york)': False,\n",
       "  'contains(attempt)': True,\n",
       "  'contains(thriller)': False,\n",
       "  'contains(scream)': False,\n",
       "  'contains(peter)': False,\n",
       "  'contains(husband)': False,\n",
       "  'contains(fiction)': False,\n",
       "  'contains(happens)': False,\n",
       "  'contains(hero)': False,\n",
       "  'contains(novel)': False,\n",
       "  'contains(note)': False,\n",
       "  'contains(hope)': False,\n",
       "  'contains(king)': False,\n",
       "  'contains(yes)': False,\n",
       "  'contains(says)': False,\n",
       "  'contains(tells)': True,\n",
       "  'contains(quickly)': True,\n",
       "  'contains(romantic)': False,\n",
       "  'contains(dog)': False,\n",
       "  'contains(oscar)': False,\n",
       "  'contains(stupid)': False,\n",
       "  'contains(possible)': False,\n",
       "  'contains(saw)': False,\n",
       "  'contains(lead)': False,\n",
       "  'contains(career)': False,\n",
       "  'contains(murder)': False,\n",
       "  'contains(extremely)': True,\n",
       "  'contains(manages)': False,\n",
       "  'contains(god)': False,\n",
       "  'contains(mostly)': False,\n",
       "  'contains(wonder)': False,\n",
       "  'contains(particularly)': False,\n",
       "  'contains(future)': False,\n",
       "  'contains(fans)': False,\n",
       "  'contains(sound)': False,\n",
       "  'contains(worse)': False,\n",
       "  'contains(piece)': False,\n",
       "  'contains(involving)': False,\n",
       "  'contains(de)': False,\n",
       "  'contains(appears)': True,\n",
       "  'contains(planet)': False,\n",
       "  'contains(paul)': False,\n",
       "  'contains(involved)': False,\n",
       "  'contains(mean)': False,\n",
       "  'contains(none)': False,\n",
       "  'contains(taking)': False,\n",
       "  'contains(hours)': False,\n",
       "  'contains(laugh)': False,\n",
       "  'contains(police)': True,\n",
       "  'contains(sets)': False,\n",
       "  'contains(attention)': False,\n",
       "  'contains(co)': False,\n",
       "  'contains(hell)': False,\n",
       "  'contains(eventually)': False,\n",
       "  'contains(single)': True,\n",
       "  'contains(fall)': False,\n",
       "  'contains(falls)': False,\n",
       "  'contains(material)': False,\n",
       "  'contains(emotional)': False,\n",
       "  'contains(power)': False,\n",
       "  'contains(late)': True,\n",
       "  'contains(lack)': False,\n",
       "  'contains(dr)': False,\n",
       "  'contains(van)': False,\n",
       "  'contains(result)': False,\n",
       "  'contains(elements)': True,\n",
       "  'contains(meet)': False,\n",
       "  'contains(smith)': False,\n",
       "  'contains(science)': False,\n",
       "  'contains(experience)': False,\n",
       "  'contains(bring)': False,\n",
       "  'contains(wild)': False,\n",
       "  'contains(living)': False,\n",
       "  'contains(theater)': False,\n",
       "  'contains(interest)': False,\n",
       "  'contains(leads)': False,\n",
       "  'contains(word)': False,\n",
       "  'contains(feature)': False,\n",
       "  'contains(battle)': False,\n",
       "  'contains(girls)': False,\n",
       "  'contains(alone)': False,\n",
       "  'contains(obviously)': False,\n",
       "  'contains(george)': False,\n",
       "  'contains(within)': False,\n",
       "  'contains(usually)': False,\n",
       "  'contains(enjoy)': False,\n",
       "  'contains(guess)': False,\n",
       "  'contains(among)': False,\n",
       "  'contains(taken)': False,\n",
       "  'contains(feeling)': False,\n",
       "  'contains(laughs)': False,\n",
       "  'contains(aliens)': False,\n",
       "  'contains(talk)': False,\n",
       "  'contains(chance)': False,\n",
       "  'contains(talent)': False,\n",
       "  'contains(middle)': False,\n",
       "  'contains(number)': True,\n",
       "  'contains(easy)': False,\n",
       "  'contains(across)': False,\n",
       "  'contains(needs)': False,\n",
       "  'contains(attempts)': False,\n",
       "  'contains(happen)': False,\n",
       "  'contains(television)': True,\n",
       "  'contains(chris)': False,\n",
       "  'contains(deal)': False,\n",
       "  'contains(poor)': False,\n",
       "  'contains(form)': False,\n",
       "  'contains(girlfriend)': False,\n",
       "  'contains(viewer)': True,\n",
       "  'contains(release)': False,\n",
       "  'contains(killed)': False,\n",
       "  'contains(forced)': False,\n",
       "  'contains(whether)': False,\n",
       "  'contains(wonderful)': False,\n",
       "  'contains(feels)': False,\n",
       "  'contains(oh)': False,\n",
       "  'contains(tale)': True,\n",
       "  'contains(serious)': False,\n",
       "  'contains(expect)': False,\n",
       "  'contains(except)': False,\n",
       "  'contains(light)': False,\n",
       "  'contains(success)': False,\n",
       "  'contains(features)': False,\n",
       "  'contains(premise)': False,\n",
       "  'contains(happy)': False,\n",
       "  'contains(words)': False,\n",
       "  'contains(leave)': False,\n",
       "  'contains(important)': False,\n",
       "  'contains(meets)': False,\n",
       "  'contains(history)': False,\n",
       "  'contains(giving)': False,\n",
       "  'contains(crew)': False,\n",
       "  'contains(type)': False,\n",
       "  'contains(call)': False,\n",
       "  'contains(turned)': False,\n",
       "  'contains(released)': False,\n",
       "  'contains(parents)': False,\n",
       "  'contains(art)': False,\n",
       "  'contains(impressive)': False,\n",
       "  'contains(mission)': False,\n",
       "  'contains(working)': False,\n",
       "  'contains(seemed)': False,\n",
       "  'contains(score)': False,\n",
       "  'contains(told)': False,\n",
       "  'contains(recent)': False,\n",
       "  'contains(robin)': False,\n",
       "  'contains(basically)': False,\n",
       "  'contains(entertainment)': False,\n",
       "  'contains(america)': False,\n",
       "  'contains(surprise)': False,\n",
       "  'contains(apparently)': False,\n",
       "  'contains(easily)': False,\n",
       "  'contains(ryan)': False,\n",
       "  'contains(cool)': True,\n",
       "  'contains(stuff)': True,\n",
       "  'contains(cop)': True,\n",
       "  'contains(change)': False,\n",
       "  'contains(williams)': False,\n",
       "  'contains(crime)': False,\n",
       "  'contains(office)': False,\n",
       "  'contains(parts)': False,\n",
       "  'contains(somehow)': False,\n",
       "  'contains(sequel)': False,\n",
       "  'contains(william)': False,\n",
       "  'contains(cut)': False,\n",
       "  'contains(die)': False,\n",
       "  'contains(jones)': False,\n",
       "  'contains(credits)': False,\n",
       "  'contains(batman)': False,\n",
       "  'contains(suspense)': False,\n",
       "  'contains(brings)': False,\n",
       "  'contains(events)': False,\n",
       "  'contains(reality)': False,\n",
       "  'contains(local)': False,\n",
       "  'contains(talking)': False,\n",
       "  'contains(difficult)': False,\n",
       "  'contains(using)': False,\n",
       "  'contains(went)': False,\n",
       "  'contains(writing)': False,\n",
       "  'contains(remember)': False,\n",
       "  'contains(near)': False,\n",
       "  'contains(straight)': False,\n",
       "  'contains(hilarious)': False,\n",
       "  'contains(ago)': False,\n",
       "  'contains(certain)': False,\n",
       "  'contains(ben)': False,\n",
       "  'contains(kid)': False,\n",
       "  'contains(slow)': False,\n",
       "  'contains(blood)': False,\n",
       "  'contains(mystery)': False,\n",
       "  'contains(complete)': True,\n",
       "  'contains(red)': False,\n",
       "  'contains(popular)': False,\n",
       "  'contains(effective)': False,\n",
       "  'contains(fast)': False,\n",
       "  'contains(flick)': False,\n",
       "  'contains(due)': False,\n",
       "  'contains(runs)': False,\n",
       "  'contains(gone)': False,\n",
       "  'contains(return)': False,\n",
       "  'contains(presence)': False,\n",
       "  'contains(quality)': False,\n",
       "  'contains(dramatic)': False,\n",
       "  'contains(filmmakers)': False,\n",
       "  'contains(age)': False,\n",
       "  'contains(brothers)': False,\n",
       "  'contains(business)': False,\n",
       "  'contains(general)': False,\n",
       "  'contains(rock)': False,\n",
       "  'contains(sexual)': False,\n",
       "  'contains(present)': False,\n",
       "  'contains(surprisingly)': False,\n",
       "  'contains(anyway)': False,\n",
       "  'contains(uses)': False,\n",
       "  'contains(personal)': False,\n",
       "  'contains(figure)': False,\n",
       "  'contains(smart)': False,\n",
       "  'contains(ways)': False,\n",
       "  'contains(decides)': False,\n",
       "  'contains(annoying)': False,\n",
       "  'contains(begin)': False,\n",
       "  'contains(somewhat)': False,\n",
       "  'contains(shots)': False,\n",
       "  'contains(rich)': False,\n",
       "  'contains(minute)': False,\n",
       "  'contains(law)': False,\n",
       "  'contains(previous)': False,\n",
       "  'contains(jim)': False,\n",
       "  'contains(successful)': False,\n",
       "  'contains(harry)': False,\n",
       "  'contains(water)': False,\n",
       "  'contains(similar)': False,\n",
       "  'contains(absolutely)': False,\n",
       "  'contains(motion)': False,\n",
       "  'contains(former)': False,\n",
       "  'contains(strange)': False,\n",
       "  'contains(came)': False,\n",
       "  'contains(follow)': False,\n",
       "  'contains(read)': False,\n",
       "  'contains(project)': False,\n",
       "  'contains(million)': False,\n",
       "  'contains(secret)': False,\n",
       "  'contains(starring)': False,\n",
       "  'contains(clear)': True,\n",
       "  'contains(familiar)': False,\n",
       "  'contains(romance)': False,\n",
       "  'contains(intelligent)': False,\n",
       "  'contains(third)': False,\n",
       "  'contains(excellent)': False,\n",
       "  'contains(amazing)': False,\n",
       "  'contains(party)': False,\n",
       "  'contains(budget)': False,\n",
       "  'contains(eye)': False,\n",
       "  'contains(actress)': False,\n",
       "  'contains(prison)': False,\n",
       "  'contains(latest)': False,\n",
       "  'contains(means)': False,\n",
       "  'contains(company)': False,\n",
       "  'contains(towards)': True,\n",
       "  'contains(predictable)': True,\n",
       "  'contains(powerful)': False,\n",
       "  'contains(bob)': False,\n",
       "  'contains(beyond)': False,\n",
       "  'contains(visual)': False,\n",
       "  'contains(leaves)': False,\n",
       "  'contains(r)': True,\n",
       "  'contains(nature)': False,\n",
       "  'contains(following)': False,\n",
       "  'contains(villain)': False,\n",
       "  'contains(leaving)': False,\n",
       "  'contains(animated)': False,\n",
       "  'contains(low)': False,\n",
       "  'contains(b)': False,\n",
       "  'contains(bill)': False,\n",
       "  'contains(sam)': False,\n",
       "  'contains(filled)': False,\n",
       "  'contains(wars)': False,\n",
       "  'contains(questions)': False,\n",
       "  'contains(cinema)': False,\n",
       "  'contains(message)': False,\n",
       "  'contains(box)': False,\n",
       "  'contains(moving)': False,\n",
       "  'contains(country)': False,\n",
       "  'contains(usual)': False,\n",
       "  'contains(martin)': False,\n",
       "  'contains(definitely)': False,\n",
       "  'contains(add)': False,\n",
       "  'contains(large)': False,\n",
       "  'contains(clever)': False,\n",
       "  'contains(create)': False,\n",
       "  'contains(felt)': False,\n",
       "  'contains(stories)': False,\n",
       "  'contains(brilliant)': False,\n",
       "  'contains(ones)': False,\n",
       "  'contains(giant)': False,\n",
       "  'contains(situation)': False,\n",
       "  'contains(murphy)': False,\n",
       "  'contains(break)': False,\n",
       "  'contains(opens)': False,\n",
       "  'contains(scary)': False,\n",
       "  'contains(doubt)': False,\n",
       "  'contains(drug)': False,\n",
       "  'contains(bunch)': False,\n",
       "  'contains(thinking)': False,\n",
       "  'contains(solid)': False,\n",
       "  'contains(effect)': False,\n",
       "  'contains(learn)': False,\n",
       "  'contains(move)': False,\n",
       "  'contains(force)': False,\n",
       "  'contains(potential)': False,\n",
       "  'contains(seriously)': False,\n",
       "  'contains(follows)': False,\n",
       "  'contains(saying)': False,\n",
       "  'contains(huge)': False,\n",
       "  'contains(class)': False,\n",
       "  'contains(plan)': False,\n",
       "  'contains(agent)': False,\n",
       "  'contains(created)': False,\n",
       "  'contains(unlike)': False,\n",
       "  'contains(pay)': False,\n",
       "  'contains(non)': False,\n",
       "  'contains(married)': False,\n",
       "  'contains(mark)': False,\n",
       "  'contains(sweet)': False,\n",
       "  'contains(perfectly)': False,\n",
       "  'contains(ex)': False,\n",
       "  'contains(realize)': False,\n",
       "  'contains(audiences)': False,\n",
       "  'contains(took)': False,\n",
       "  'contains(decent)': False,\n",
       "  'contains(likely)': True,\n",
       "  'contains(dream)': False,\n",
       "  'contains(view)': False,\n",
       "  'contains(scott)': False,\n",
       "  'contains(subject)': False,\n",
       "  'contains(understand)': False,\n",
       "  'contains(happened)': False,\n",
       "  'contains(enjoyable)': False,\n",
       "  'contains(studio)': False,\n",
       "  'contains(immediately)': True,\n",
       "  'contains(open)': False,\n",
       "  'contains(e)': False,\n",
       "  'contains(points)': False,\n",
       "  'contains(heard)': False,\n",
       "  'contains(viewers)': False,\n",
       "  'contains(cameron)': False,\n",
       "  'contains(truman)': False,\n",
       "  'contains(bruce)': False,\n",
       "  'contains(frank)': False,\n",
       "  'contains(private)': False,\n",
       "  'contains(stay)': False,\n",
       "  'contains(fails)': False,\n",
       "  'contains(impossible)': False,\n",
       "  'contains(cold)': False,\n",
       "  'contains(richard)': False,\n",
       "  'contains(overall)': False,\n",
       "  'contains(merely)': False,\n",
       "  'contains(exciting)': False,\n",
       "  'contains(mess)': True,\n",
       "  'contains(chase)': False,\n",
       "  'contains(free)': False,\n",
       "  'contains(ten)': False,\n",
       "  'contains(neither)': False,\n",
       "  'contains(wanted)': False,\n",
       "  'contains(gun)': False,\n",
       "  'contains(appear)': False,\n",
       "  'contains(carter)': False,\n",
       "  'contains(escape)': True,\n",
       "  'contains(ultimately)': True,\n",
       "  'contains(fan)': False,\n",
       "  'contains(inside)': False,\n",
       "  'contains(favorite)': False,\n",
       "  'contains(modern)': False,\n",
       "  'contains(l)': False,\n",
       "  'contains(wedding)': False,\n",
       "  'contains(stone)': False,\n",
       "  'contains(trek)': False,\n",
       "  'contains(brought)': False,\n",
       "  'contains(trouble)': False,\n",
       "  'contains(otherwise)': False,\n",
       "  'contains(tim)': False,\n",
       "  'contains(allen)': False,\n",
       "  'contains(bond)': False,\n",
       "  'contains(society)': False,\n",
       "  'contains(liked)': False,\n",
       "  'contains(dumb)': False,\n",
       "  'contains(musical)': False,\n",
       "  'contains(stand)': False,\n",
       "  'contains(political)': False,\n",
       "  'contains(various)': False,\n",
       "  'contains(talented)': False,\n",
       "  'contains(particular)': False,\n",
       "  'contains(west)': False,\n",
       "  'contains(state)': False,\n",
       "  'contains(keeps)': False,\n",
       "  'contains(english)': False,\n",
       "  'contains(silly)': False,\n",
       "  'contains(u)': False,\n",
       "  'contains(situations)': False,\n",
       "  'contains(park)': False,\n",
       "  'contains(teen)': True,\n",
       "  'contains(rating)': True,\n",
       "  'contains(slightly)': False,\n",
       "  'contains(steve)': False,\n",
       "  'contains(truth)': False,\n",
       "  'contains(air)': False,\n",
       "  'contains(element)': False,\n",
       "  'contains(joke)': False,\n",
       "  'contains(spend)': False,\n",
       "  'contains(key)': False,\n",
       "  'contains(biggest)': False,\n",
       "  'contains(members)': False,\n",
       "  'contains(effort)': False,\n",
       "  'contains(government)': False,\n",
       "  'contains(focus)': False,\n",
       "  'contains(eddie)': False,\n",
       "  'contains(soundtrack)': True,\n",
       "  'contains(hands)': False,\n",
       "  'contains(earlier)': False,\n",
       "  'contains(chan)': False,\n",
       "  'contains(purpose)': False,\n",
       "  'contains(today)': False,\n",
       "  'contains(showing)': False,\n",
       "  'contains(memorable)': True,\n",
       "  'contains(six)': True,\n",
       "  'contains(cannot)': False,\n",
       "  'contains(max)': False,\n",
       "  'contains(offers)': False,\n",
       "  'contains(rated)': False,\n",
       "  'contains(mars)': False,\n",
       "  'contains(heavy)': False,\n",
       "  'contains(totally)': False,\n",
       "  'contains(control)': False,\n",
       "  'contains(credit)': False,\n",
       "  'contains(fi)': False,\n",
       "  'contains(woody)': False,\n",
       "  'contains(ideas)': False,\n",
       "  'contains(sci)': False,\n",
       "  'contains(wait)': False,\n",
       "  'contains(sit)': False,\n",
       "  'contains(female)': False,\n",
       "  'contains(ask)': False,\n",
       "  'contains(waste)': False,\n",
       "  'contains(terrible)': False,\n",
       "  'contains(depth)': False,\n",
       "  'contains(simon)': False,\n",
       "  'contains(aspect)': False,\n",
       "  'contains(list)': False,\n",
       "  'contains(mary)': False,\n",
       "  'contains(sister)': False,\n",
       "  'contains(animation)': False,\n",
       "  'contains(entirely)': False,\n",
       "  'contains(fear)': False,\n",
       "  'contains(steven)': False,\n",
       "  'contains(moves)': False,\n",
       "  'contains(actual)': False,\n",
       "  'contains(army)': False,\n",
       "  'contains(british)': False,\n",
       "  'contains(constantly)': False,\n",
       "  'contains(fire)': False,\n",
       "  'contains(convincing)': False,\n",
       "  'contains(setting)': False,\n",
       "  'contains(gave)': False,\n",
       "  'contains(tension)': False,\n",
       "  'contains(street)': False,\n",
       "  'contains(brief)': False,\n",
       "  'contains(ridiculous)': False,\n",
       "  'contains(cinematography)': False,\n",
       "  'contains(typical)': False,\n",
       "  'contains(nick)': False,\n",
       "  'contains(screenwriter)': False,\n",
       "  'contains(ability)': False,\n",
       "  'contains(spent)': False,\n",
       "  'contains(quick)': True,\n",
       "  'contains(violent)': False,\n",
       "  'contains(atmosphere)': False,\n",
       "  'contains(subtle)': False,\n",
       "  'contains(expected)': False,\n",
       "  'contains(fairly)': False,\n",
       "  'contains(seven)': False,\n",
       "  'contains(killing)': False,\n",
       "  'contains(tone)': False,\n",
       "  'contains(master)': False,\n",
       "  'contains(disaster)': False,\n",
       "  'contains(lots)': False,\n",
       "  'contains(thinks)': False,\n",
       "  'contains(song)': False,\n",
       "  'contains(cheap)': False,\n",
       "  'contains(suddenly)': False,\n",
       "  'contains(background)': False,\n",
       "  'contains(club)': False,\n",
       "  'contains(willis)': False,\n",
       "  'contains(whatever)': False,\n",
       "  'contains(highly)': False,\n",
       "  'contains(sees)': False,\n",
       "  'contains(complex)': False,\n",
       "  'contains(greatest)': False,\n",
       "  'contains(impact)': False,\n",
       "  'contains(beauty)': False,\n",
       "  'contains(front)': False,\n",
       "  'contains(humans)': False,\n",
       "  'contains(indeed)': False,\n",
       "  'contains(flat)': False,\n",
       "  'contains(grace)': False,\n",
       "  'contains(wrote)': False,\n",
       "  'contains(amusing)': False,\n",
       "  'contains(ii)': False,\n",
       "  'contains(mike)': False,\n",
       "  'contains(cute)': True,\n",
       "  'contains(dull)': False,\n",
       "  'contains(minor)': False,\n",
       "  'contains(recently)': False,\n",
       "  'contains(hate)': False,\n",
       "  'contains(outside)': False,\n",
       "  'contains(plenty)': False,\n",
       "  'contains(wish)': False,\n",
       "  'contains(godzilla)': False,\n",
       "  'contains(college)': False,\n",
       "  'contains(titanic)': False,\n",
       "  'contains(sounds)': True,\n",
       "  'contains(telling)': True,\n",
       "  'contains(sight)': False,\n",
       "  'contains(double)': False,\n",
       "  'contains(cinematic)': False,\n",
       "  'contains(queen)': False,\n",
       "  'contains(hold)': False,\n",
       "  'contains(meanwhile)': False,\n",
       "  'contains(awful)': True,\n",
       "  'contains(clearly)': False,\n",
       "  'contains(theme)': False,\n",
       "  'contains(hear)': False,\n",
       "  'contains(x)': False,\n",
       "  'contains(amount)': False,\n",
       "  'contains(baby)': False,\n",
       "  'contains(approach)': False,\n",
       "  'contains(dreams)': False,\n",
       "  'contains(shown)': False,\n",
       "  'contains(island)': False,\n",
       "  'contains(reasons)': False,\n",
       "  'contains(charm)': False,\n",
       "  'contains(miss)': False,\n",
       "  'contains(longer)': False,\n",
       "  'contains(common)': False,\n",
       "  'contains(sean)': False,\n",
       "  'contains(carry)': False,\n",
       "  'contains(believable)': False,\n",
       "  'contains(realistic)': False,\n",
       "  'contains(chemistry)': False,\n",
       "  'contains(possibly)': False,\n",
       "  'contains(casting)': False,\n",
       "  'contains(carrey)': False,\n",
       "  'contains(french)': False,\n",
       "  'contains(trailer)': False,\n",
       "  'contains(tough)': False,\n",
       "  'contains(produced)': False,\n",
       "  'contains(imagine)': False,\n",
       "  'contains(choice)': False,\n",
       "  'contains(ride)': False,\n",
       "  'contains(somewhere)': False,\n",
       "  'contains(hot)': False,\n",
       "  'contains(race)': False,\n",
       "  'contains(road)': False,\n",
       "  'contains(leader)': False,\n",
       "  'contains(thin)': False,\n",
       "  'contains(jerry)': False,\n",
       "  'contains(slowly)': False,\n",
       "  'contains(delivers)': False,\n",
       "  'contains(detective)': False,\n",
       "  'contains(brown)': False,\n",
       "  'contains(jackson)': False,\n",
       "  'contains(member)': False,\n",
       "  'contains(provide)': False,\n",
       "  'contains(president)': False,\n",
       "  'contains(puts)': False,\n",
       "  'contains(asks)': False,\n",
       "  'contains(critics)': False,\n",
       "  'contains(appearance)': False,\n",
       "  'contains(famous)': False,\n",
       "  'contains(okay)': False,\n",
       "  'contains(intelligence)': False,\n",
       "  'contains(energy)': False,\n",
       "  'contains(sent)': False,\n",
       "  'contains(spielberg)': False,\n",
       "  'contains(development)': False,\n",
       "  'contains(etc)': False,\n",
       "  'contains(language)': False,\n",
       "  'contains(blue)': False,\n",
       "  'contains(proves)': False,\n",
       "  'contains(vampire)': False,\n",
       "  'contains(seemingly)': False,\n",
       "  'contains(basic)': False,\n",
       "  'contains(caught)': False,\n",
       "  'contains(decide)': False,\n",
       "  'contains(opportunity)': False,\n",
       "  'contains(incredibly)': False,\n",
       "  'contains(images)': False,\n",
       "  'contains(band)': False,\n",
       "  'contains(j)': False,\n",
       "  'contains(writers)': False,\n",
       "  ...},\n",
       " 'neg')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresets[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train_set, test_set and perform classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88\n",
      "Most Informative Features\n",
      "   contains(outstanding) = True              pos : neg    =     10.4 : 1.0\n",
      "        contains(seagal) = True              neg : pos    =      8.7 : 1.0\n",
      "         contains(mulan) = True              pos : neg    =      8.1 : 1.0\n",
      "   contains(wonderfully) = True              pos : neg    =      6.3 : 1.0\n",
      "         contains(damon) = True              pos : neg    =      5.7 : 1.0\n",
      "          contains(lame) = True              neg : pos    =      5.6 : 1.0\n",
      "        contains(wasted) = True              neg : pos    =      5.6 : 1.0\n",
      "         contains(awful) = True              neg : pos    =      5.4 : 1.0\n",
      "         contains(flynt) = True              pos : neg    =      5.1 : 1.0\n",
      "    contains(ridiculous) = True              neg : pos    =      5.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "print(nltk.classify.accuracy(classifier, test_set))\n",
    "\n",
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK gives us 88% accuracy, which isn't bad, but our home-made naive algorithm also achieved a respectable 80%.\n",
    "\n",
    "\n",
    "What improvements could we have made? Obviously, we could have used more data, or – in our home-grown model select words that discriminate between good and bad reviews. We could have used n-grams, e.g., to catch \"not bad\" as a postitive sentiment."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
